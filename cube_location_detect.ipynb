{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 照片拍攝，透過opencv拍照"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "num = 0\n",
    "\n",
    "while cap.isOpened():\n",
    "\n",
    "    succes, img = cap.read()\n",
    "\n",
    "    k = cv2.waitKey(5)\n",
    "\n",
    "    if k == ord(\"q\"):\n",
    "        break\n",
    "    elif k == ord('s'): # wait for 's' key to save and exit\n",
    "        cv2.imwrite('images/img' + str(num) + '.png', img)\n",
    "        print(\"image saved!\")\n",
    "        num += 1\n",
    "\n",
    "    cv2.imshow('Img',img)\n",
    "\n",
    "cap.release()\n",
    "\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 繪圖函數宣告 一定要先執行！！"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 繪製函數定義\n",
    "import numpy as np\n",
    "def draw_axis(img, corners, image_points):\n",
    "    corner = tuple(corners[0].ravel())\n",
    "    img = cv2.line(img, corner, tuple(np.int16(image_points[0].ravel())), (255,0,0), 5)\n",
    "    img = cv2.line(img, corner, tuple(np.int16(image_points[1].ravel())), (0,255,0), 5)\n",
    "    img = cv2.line(img, corner, tuple(np.int16(image_points[2].ravel())), (0,0,255), 5)\n",
    "    return img\n",
    "def draw_xy_lines(img, image_points):\n",
    "    img = cv2.line(img, tuple(np.int16(image_points[0].ravel())), tuple(np.int16(image_points[1].ravel())), (0,0,0), 5)\n",
    "    img = cv2.line(img, tuple(np.int16(image_points[1].ravel())), tuple(np.int16(image_points[2].ravel())), (0,0,0), 5)\n",
    "    return img\n",
    "def draw_z_lines(img, image_points):\n",
    "    img = cv2.line(img, tuple(np.int16(image_points[1].ravel())), tuple(np.int16(image_points[3].ravel())), (128,128,0), 5)\n",
    "    return img"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 鏡頭校正"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import glob\n",
    "import pickle\n",
    "\n",
    "# 定義所使用的棋盤格格式\n",
    "chessboardSize = (9,6)\n",
    "# 亞像素計算的迭代終止條件\n",
    "criteria = (cv2.TERM_CRITERIA_EPS + cv2.TERM_CRITERIA_MAX_ITER, 30, 0.001)\n",
    "\n",
    "\n",
    "# 棋盤座標矩陣序列矩陣創立\n",
    "objp = np.zeros((chessboardSize[0] * chessboardSize[1], 3), np.float32)\n",
    "objp[:,:2] = np.mgrid[0:chessboardSize[0],0:chessboardSize[1]].T.reshape(-1,2)\n",
    "\n",
    "# 棋盤格單格在真實圖片中的寬度大小\n",
    "size_of_chessboard_squares_mm = 19\n",
    "objp = objp * size_of_chessboard_squares_mm\n",
    "\n",
    "#分別創建用於儲存真實座標與對應像素座標的陣列，陣列中的每個元素代表的是每張圖對應到一組棋盤座標與圖片像素座標\n",
    "objpoints = [] # 3d point in real world space\n",
    "imgpoints = [] # 2d points in image plane.\n",
    "\n",
    "# 抓取指定路徑所有檔案路徑，輸出為list[str]\n",
    "images = glob.glob('your/images/location/*.png')\n",
    "# images = glob.glob('camera/images/*.png')\n",
    "\n",
    "for result_img in images:\n",
    "\n",
    "    img = cv2.imread(result_img)\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # 尋找棋盤格角點\n",
    "    ret, corners = cv2.findChessboardCorners(gray, chessboardSize, None)\n",
    "\n",
    "    # 若尋找成功就將對應的棋盤座標點與像素點新增近objpoints和imgpoints list當中\n",
    "    if ret == True:\n",
    "\n",
    "        objpoints.append(objp)\n",
    "        # 將找到的圖像像素座標點進行亞像素修正處理，以取得更精確的像素座標位置\n",
    "        corners2 = cv2.cornerSubPix(gray, corners, (11,11), (-1,-1), criteria)\n",
    "        imgpoints.append(corners)\n",
    "\n",
    "        cv2.drawChessboardCorners(img, chessboardSize, corners2, ret)\n",
    "        cv2.imshow('img', img)\n",
    "        cv2.waitKey(1000)\n",
    "\n",
    "\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "\n",
    "# 使用讀取到的圖片座標點與對應的棋盤座標進行鏡頭校正\n",
    "ret, cameraMatrix, dist, rvecs, tvecs = cv2.calibrateCamera(objpoints, imgpoints, gray.shape[::-1], None, None)\n",
    "\n",
    "# 儲存鏡頭內參成pkl檔，以便之後調用，而無需重新計算鏡頭內參矩陣與畸變係數\n",
    "pickle.dump((cameraMatrix, dist), open( \"calibration.pkl\", \"wb\" ))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 桌面座標系建立"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 視窗建立函數"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tkinter as tk\n",
    "\n",
    "# 創建獲取長寬表單視窗\n",
    "def setHeightWin():\n",
    "    root = tk.Tk()\n",
    "    root.title(\"Input Form\")\n",
    "\n",
    "    # 獲取螢幕寬高\n",
    "    screen_width = root.winfo_screenwidth()\n",
    "    screen_height = root.winfo_screenheight()\n",
    "\n",
    "    # 設置視窗寬高(像素)\n",
    "    window_width = 400  \n",
    "    window_height = 150 \n",
    "\n",
    "    # 計算視窗左上角座標\n",
    "    x = (screen_width - window_width) // 2\n",
    "    y = (screen_height - window_height) // 2\n",
    "\n",
    "    # 視窗生成\n",
    "    root.geometry(f\"{window_width}x{window_height}+{x}+{y}\")\n",
    "\n",
    "    # 創建label, entry元件顯示讀取參數\n",
    "    label_height = tk.Label(root, text=\"Height:\", font=(\"Helvetica\", 14))\n",
    "    label_height.pack()\n",
    "\n",
    "    entry_height = tk.Entry(root, font=(\"Helvetica\", 14),justify=\"center\")\n",
    "    entry_height.pack()\n",
    "\n",
    "    label_width = tk.Label(root, text=\"Width:\", font=(\"Helvetica\", 14))\n",
    "    label_width.pack()\n",
    "\n",
    "    entry_width = tk.Entry(root, font=(\"Helvetica\", 14),justify=\"center\")\n",
    "    entry_width.pack()\n",
    "    \n",
    "    result = []\n",
    "    # 處理送出的表單\n",
    "    def submit_form():\n",
    "        height = entry_height.get()\n",
    "        width = entry_width.get()\n",
    "        result.extend([height, width])\n",
    "\n",
    "        if any(item == \"\" for item in result):# 當缺少參數的時候就將參數清空，不採取動作\n",
    "            result.clear()\n",
    "            return\n",
    "        # 參數沒問題就銷毀視窗，回傳數值\n",
    "        root.destroy()\n",
    "    # 將enter綁定送出表單\n",
    "    root.bind('<Return>', lambda event=None: submit_form())\n",
    "    # 創建\"送出\"按鈕\n",
    "    submit_button = tk.Button(root, text=\"送出\", command=submit_form,width=10,height=1,font=(\"Helveticsa\",14))\n",
    "    submit_button.pack()\n",
    "\n",
    "    # 啟動Tkinter主循環\n",
    "    root.mainloop()\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 主程式"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "\n",
    "#讀取寬高參數\n",
    "square_height,square_width = setHeightWin()\n",
    "square_object_points=np.float32([(0,0,0),(square_width,0,0),(square_width,square_height,0),(0,square_height,0)])\n",
    "\n",
    "with open('camera/calibration.pkl', 'rb') as file:\n",
    "    mtx,dist = pickle.load(file)\n",
    "\n",
    "image = cv2.imread('pnp_test_img/img101.png')  # 載入圖片\n",
    "height =480\n",
    "scale = height / image.shape[0]\n",
    "image = cv2.resize(image, None, fx=scale, fy=scale, interpolation=cv2.INTER_LINEAR)\n",
    "drawing_image = image.copy()\n",
    "Adjusted_image = None \n",
    "\n",
    "isDrawing = True\n",
    "isAdjusting = False\n",
    "isFirstDraw = True\n",
    "square_image_points = []\n",
    "line_thickness = 2\n",
    "# 回調函數，處理滑鼠事件\n",
    "def draw_line(event, x, y, flags, param):\n",
    "    global line_start, line_end, isDrawing,drawing_image,Adjusted_image,square_image_points,isAdjusting,isFirstDraw,line_thickness\n",
    "    #偵測事件\n",
    "    if event == cv2.EVENT_LBUTTONDOWN:  # 當按下左鍵\n",
    "        if isDrawing:\n",
    "            if isFirstDraw:\n",
    "                isFirstDraw = False\n",
    "            else :\n",
    "                cv2.line(drawing_image,square_image_points[-1],(x,y),(255,0,0),line_thickness)\n",
    "            if len(square_image_points) < 4:\n",
    "                square_image_points.append((x,y))\n",
    "            if len(square_image_points)==4:\n",
    "                isDrawing = False\n",
    "                isAdjusting = True\n",
    "                frame_update()\n",
    "        elif isAdjusting:\n",
    "            distances = np.linalg.norm(np.array(square_image_points) - np.array((x,y)), axis=1)\n",
    "            nearest_index = np.argmin(distances)\n",
    "            square_image_points[nearest_index]=(x,y)\n",
    "            frame_update()\n",
    "    elif event == cv2.EVENT_MOUSEMOVE:  # 當滑鼠移動\n",
    "        if isDrawing and not isFirstDraw:\n",
    "            temp_image = drawing_image.copy()  # 複製圖像而非變更原圖\n",
    "            cv2.line(temp_image, square_image_points[-1], (x, y), (0, 255, 0), line_thickness)\n",
    "            cv2.imshow('Set Table axis', temp_image)\n",
    "        if isAdjusting:\n",
    "            cv2.imshow('Set Table axis', Adjusted_image)\n",
    "\n",
    "    elif event == cv2.EVENT_MOUSEWHEEL: # 當滑鼠滾輪滾動\n",
    "        delta = flags\n",
    "        if delta > 0:\n",
    "            if line_thickness==3:\n",
    "                pass\n",
    "            else:\n",
    "                line_thickness+=1\n",
    "        elif delta < 0:\n",
    "            if line_thickness == 1:\n",
    "                pass\n",
    "            else:\n",
    "                line_thickness-=1\n",
    "        frame_update()\n",
    "\n",
    "# 創建視窗\n",
    "cv2.namedWindow('Set Table axis')\n",
    "# 綁定監聽滑鼠事件，綁定處理事件回調函數\n",
    "cv2.setMouseCallback('Set Table axis', draw_line)\n",
    "\n",
    "def frame_update(): # 進行畫面更新\n",
    "    global Adjusted_image, square_image_points,line_thickness,rvecs,tvecs\n",
    "    Adjusted_image=image.copy()\n",
    "    cv2.polylines(Adjusted_image, [np.array(square_image_points)], isClosed=True, color=(0, 255, 0), thickness=line_thickness)\n",
    "    for coordinate,point in zip(square_object_points,square_image_points):\n",
    "        cv2.putText(Adjusted_image, f\"{list(coordinate)}\", point, cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255,0, 255), 2)\n",
    "    square_img_points = np.float32(square_image_points)\n",
    "    # print(square_img_points)\n",
    "    ret,rvecs,tvecs = cv2.solvePnP(square_object_points,square_img_points,mtx,dist)\n",
    "    # print(rvecs)\n",
    "    axis = np.float32([[100,0,0], [0,100,0], [0,0,100]]).reshape(-1,3)\n",
    "    axis_img_points, _ = cv2.projectPoints(axis, rvecs, tvecs, mtx, dist)\n",
    "    draw_axis(Adjusted_image,square_img_points.astype(int),axis_img_points)\n",
    "\n",
    "# 顯示圖像\n",
    "while True:\n",
    "    if not isAdjusting:\n",
    "        cv2.imshow('Set Table axis', drawing_image)\n",
    "    else:\n",
    "        cv2.imshow('Set Table axis', Adjusted_image)\n",
    "    key = cv2.waitKey(1)\n",
    "    if key == 27:  # 當按下ESC退出循環\n",
    "        break\n",
    "    if len(square_image_points)!=4: #確認是否四個像素座標點抓到了\n",
    "        continue\n",
    "    if key == ord(\"r\"): # Z軸對調\n",
    "        square_image_points[1],square_image_points[3]=square_image_points[3],square_image_points[1]\n",
    "        # square_coordinates[1],square_coordinates[3]=square_coordinates[3],square_coordinates[1]\n",
    "        frame_update()\n",
    "    if key == ord(\"e\"): # 變更原點\n",
    "        square_image_points=square_image_points[-1:]+ square_image_points[:-1] #前包後不包\n",
    "        frame_update()\n",
    "    if key == ord(\"w\"): # 重設長寬\n",
    "        square_height,square_width = setHeightWin()\n",
    "        square_object_points=np.float32([(0,0,0),(square_width,0,0),(square_width,square_height,0),(0,square_height,0)])\n",
    "        frame_update()\n",
    "    if key ==ord(\"q\"): # 長寬互換\n",
    "        square_height,square_width=square_width,square_height\n",
    "        square_object_points=np.float32([(0,0,0),(square_width,0,0),(square_width,square_height,0),(0,square_height,0)])\n",
    "        frame_update()\n",
    "    if key == ord(\"s\"): # 儲存真實與圖像座標和PNP計算結果\n",
    "        with open('table_points.pkl', 'wb') as file:\n",
    "                pickle.dump((square_object_points,np.float32(square_image_points)), file)\n",
    "        with open('table_solvePnP.pkl', 'wb') as file:\n",
    "                pickle.dump((rvecs,tvecs), file)\n",
    "        print(\"saved\")\n",
    "                    \n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 方塊座標系轉換至桌面座標系"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "模型讀取"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "from ultralytics import YOLO\n",
    "import numpy as np\n",
    "import cube_detector.cube_detector as CD\n",
    "import pickle\n",
    "\n",
    "model = YOLO(\"yolov8n-seg-custom.pt\")\n",
    "surface_model = YOLO('cube_surface_seg2.pt')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "方塊到桌面座標系轉換"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 照片計算"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "detector=CD.CubeDetector(model,surface_model)\n",
    "detector\n",
    "with open('test_calibration.pkl', 'rb') as file:\n",
    "    mtx,dist = pickle.load(file)\n",
    "with open('test_table_points.pkl','rb') as file:\n",
    "    table_objectPoints,table_imagePoints = pickle.load(file)\n",
    "with open('test_table_solvePnP.pkl','rb') as file:\n",
    "    table_rvec,table_tvec = pickle.load(file)\n",
    "color = \"green\"\n",
    "img = cv2.imread(\"test.jpg\")\n",
    "height =480\n",
    "scale = height / img.shape[0]\n",
    "img = cv2.resize(img, None, fx=scale, fy=scale, interpolation=cv2.INTER_LINEAR)\n",
    "#  將圖片丟入偵測器進行偵測\n",
    "result_img = detector.detect(img,index=None,color=None)\n",
    "# 讀取抓到的角點座標\n",
    "cube_imagePoints=detector.get_cube_sequence_imagePoints(color)\n",
    "# 依順序定出對應真實世界對應座標\n",
    "cube_objectPoints=np.array([(0,0,0),(0,25,0),(25,25,0),(25,0,0),(25,0,-25),(0,0,-25)])\n",
    "# 如果抓到六個點採用EPNP算法(較準確穩定)，四個點則是一般算法\n",
    "if cube_imagePoints.shape[0]==6:\n",
    "    PnP_success,cube_rvec,cube_tvec = cv2.solvePnP(cube_objectPoints.astype(float),cube_imagePoints,mtx,dist,flags=cv2.SOLVEPNP_EPNP)\n",
    "elif cube_imagePoints.shape[0]==4:\n",
    "    PnP_success,cube_rvec,cube_tvec = cv2.solvePnP(cube_objectPoints[:4].astype(float),cube_imagePoints,mtx,dist)\n",
    "#  若成功計算出來則計算出該方塊相對於桌面座標系的座標位置\n",
    "if PnP_success:\n",
    "    R1, _ = cv2.Rodrigues(cube_rvec) # 創建方塊到相機座標系的旋轉矩陣\n",
    "    R2, _ = cv2.Rodrigues(table_rvec) # 創建桌面到方塊座標系的旋轉矩陣\n",
    "    T1 = np.eye(4) #創建4*4單位矩陣\n",
    "    T2 = np.eye(4) \n",
    "    T1[:3, :3], T1[:3, 3] = R1, cube_tvec.T #  方塊座標系旋轉加平移到相機座標系 轉換矩陣\n",
    "    T2[:3, :3], T2[:3, 3] = R2, table_tvec.T # 桌面座標系旋轉加平移到相機座標系 轉換矩陣\n",
    "    T2=np.linalg.inv(T2) # 取逆矩陣，變成 相譏座標系到桌面座標系 轉換矩陣\n",
    "    transform_matrix = T2 @ T1 # 結合二者，得到方塊座標系到桌面座標系的轉換矩陣\n",
    "    transformed_point = transform_matrix @ np.array([[12.5, 12.5, -12.5, 1]]).T # 傳入方塊正中央座標，即可得到方塊在桌面座標位置了\n",
    "    # 输出结果\n",
    "    print(\"物體在桌面座標系下的座標:\\n\", transformed_point)\n",
    "# xyz座標位置線繪製\n",
    "x,y,z = transformed_point[0:3].flatten()\n",
    "xy_line_points=np.float32([[0,y,0],[x,y,0],[x,0,0],[x,y,z]]).reshape(-1,3)\n",
    "xy_line_points_img,_=cv2.projectPoints(xy_line_points,table_rvec,table_tvec,mtx,dist)\n",
    "result_img = draw_xy_lines(result_img,xy_line_points_img)\n",
    "result_img = draw_z_lines(result_img,xy_line_points_img)\n",
    "\n",
    "# xyz座標軸繪製\n",
    "axis = np.float32([[25,0,0], [0,25,0], [0,0,25]]).reshape(-1,3)\n",
    "axis_cube_img_points, _ = cv2.projectPoints(axis, cube_rvec, cube_tvec, mtx, dist)\n",
    "axis_table_img_points, _ = cv2.projectPoints(axis, table_rvec, table_tvec, mtx, dist)\n",
    "result_img=draw_axis(result_img,cube_imagePoints.astype(int),axis_cube_img_points)\n",
    "result_img=draw_axis(result_img,table_imagePoints.astype(int),axis_table_img_points)\n",
    "\n",
    "# 取得方塊輪廓計算方塊重心位置\n",
    "contour_outer = detector.get_cube_contour_outer(color)\n",
    "radius = int(0.04*cv2.arcLength(contour_outer,True))\n",
    "print(radius)\n",
    "M = cv2.moments(contour_outer)\n",
    "if M[\"m00\"] != 0:\n",
    "    centroid_X = int(M[\"m10\"] / M[\"m00\"])# 算形心x\n",
    "    centroid_Y = int(M[\"m01\"] / M[\"m00\"])# 算形心y\n",
    "# 繪製重心座標點\n",
    "result_img = cv2.circle(result_img, (centroid_X,centroid_Y),radius, (255,0,255), 2)\n",
    "\n",
    "# 繪製PNP計算所得座標點\n",
    "predict_cube_center_imagePoint = cv2.projectPoints(np.float32([x,y,z]),table_rvec,table_tvec,mtx,dist)\n",
    "predict_cube_center_imagePoint = predict_cube_center_imagePoint[0].astype(np.int16)\n",
    "\n",
    "cv2.putText(result_img, f\"{x=:.1f}, {y=:.1f}, {z=:.1f}\", (10,40), cv2.FONT_HERSHEY_SIMPLEX, 1, (128, 0, 128), 2)\n",
    "\n",
    "# 推算是否位置估計錯誤\n",
    "if np.linalg.norm(np.array((centroid_X,centroid_Y))-predict_cube_center_imagePoint)>radius:\n",
    "    cv2.putText(result_img, f\"Error\", (10,200), cv2.FONT_HERSHEY_SIMPLEX, 2, (0, 0, 255), 4)\n",
    "    result_img = cv2.circle(result_img, predict_cube_center_imagePoint.ravel(),5, (0,0,255), -1)\n",
    "else:\n",
    "    cv2.putText(result_img, f\"Ok\", (10,200), cv2.FONT_HERSHEY_SIMPLEX, 2, (0, 255, 0), 4)\n",
    "    result_img = cv2.circle(result_img, predict_cube_center_imagePoint.ravel(),5, (0,255,0), -1)\n",
    "cv2.imshow(\"result\",result_img)\n",
    "cv2.waitKey(0)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 即時偵測主程式\n",
    "鏡頭開啟很費時"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cap = cv2.VideoCapture(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "，所以真的要關閉再手動關閉"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cap.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import importlib\n",
    "\n",
    "\n",
    "importlib.reload(CD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "detector=CD.CubeDetector(model,surface_model)\n",
    "\n",
    "with open('test_calibration.pkl', 'rb') as file:\n",
    "    mtx,dist = pickle.load(file)\n",
    "with open('test_table_points.pkl','rb') as file:\n",
    "    table_objectPoints,table_imagePoints = pickle.load(file)\n",
    "with open('test_table_solvePnP.pkl','rb') as file:\n",
    "    table_rvec,table_tvec = pickle.load(file)\n",
    "color = \"green\"\n",
    "while cap.isOpened():\n",
    "    cap_success, frame = cap.read()\n",
    "    if cap_success:\n",
    "        height =480\n",
    "        scale = height / frame.shape[0]\n",
    "        frame = cv2.resize(frame, None, fx=scale, fy=scale, interpolation=cv2.INTER_LINEAR)\n",
    "        #  將圖片丟入偵測器進行偵測\n",
    "        result_img = detector.detect(frame,index=None,color=None)\n",
    "        # 讀取抓到的角點座標\n",
    "        cube_imagePoints=detector.get_cube_sequence_imagePoints(color)\n",
    "        if cube_imagePoints is None:\n",
    "            cv2.imshow(\"result\",frame)\n",
    "            if cv2.waitKey(1) & 0xFF == ord(\"q\"):\n",
    "                break\n",
    "            continue\n",
    "        # 依順序定出對應真實世界對應座標\n",
    "        cube_objectPoints=np.array([(0,0,0),(0,25,0),(25,25,0),(25,0,0),(25,0,-25),(0,0,-25)])\n",
    "        # 如果抓到六個點採用EPNP算法(較準確穩定)，四個點則是一般算法\n",
    "        if cube_imagePoints.shape[0]==6:\n",
    "            PnP_success,cube_rvec,cube_tvec = cv2.solvePnP(cube_objectPoints.astype(float),cube_imagePoints,mtx,dist,flags=cv2.SOLVEPNP_EPNP)\n",
    "        elif cube_imagePoints.shape[0]==4:\n",
    "            PnP_success,cube_rvec,cube_tvec = cv2.solvePnP(cube_objectPoints[:4].astype(float),cube_imagePoints,mtx,dist)\n",
    "        #  若成功計算出來則計算出該方塊相對於桌面座標系的座標位置\n",
    "        if PnP_success:\n",
    "            R1, _ = cv2.Rodrigues(cube_rvec) # 創建方塊到相機座標系的旋轉矩陣\n",
    "            R2, _ = cv2.Rodrigues(table_rvec) # 創建桌面到方塊座標系的旋轉矩陣\n",
    "            T1 = np.eye(4) #創建4*4單位矩陣\n",
    "            T2 = np.eye(4) \n",
    "            T1[:3, :3], T1[:3, 3] = R1, cube_tvec.T #  方塊座標系旋轉加平移到相機座標系 轉換矩陣\n",
    "            T2[:3, :3], T2[:3, 3] = R2, table_tvec.T # 桌面座標系旋轉加平移到相機座標系 轉換矩陣\n",
    "            T2=np.linalg.inv(T2) # 取逆矩陣，變成 相譏座標系到桌面座標系 轉換矩陣\n",
    "            transform_matrix = T2 @ T1 # 結合二者，得到方塊座標系到桌面座標系的轉換矩陣\n",
    "            transformed_point = transform_matrix @ np.array([[12.5, 12.5, -12.5, 1]]).T # 傳入方塊正中央座標，即可得到方塊在桌面座標位置了\n",
    "            # 输出结果\n",
    "            print(\"物體在桌面座標系下的座標:\\n\", transformed_point)\n",
    "        # xyz座標位置線繪製\n",
    "        x,y,z = transformed_point[0:3].flatten()\n",
    "        xy_line_points=np.float32([[0,y,0],[x,y,0],[x,0,0],[x,y,z]]).reshape(-1,3)\n",
    "        xy_line_points_img,_=cv2.projectPoints(xy_line_points,table_rvec,table_tvec,mtx,dist)\n",
    "        result_img = draw_xy_lines(result_img,xy_line_points_img)\n",
    "        result_img = draw_z_lines(result_img,xy_line_points_img)\n",
    "\n",
    "        # xyz座標軸繪製\n",
    "        axis = np.float32([[25,0,0], [0,25,0], [0,0,25]]).reshape(-1,3)\n",
    "        axis_cube_img_points, _ = cv2.projectPoints(axis, cube_rvec, cube_tvec, mtx, dist)\n",
    "        axis_table_img_points, _ = cv2.projectPoints(axis, table_rvec, table_tvec, mtx, dist)\n",
    "        result_img=draw_axis(result_img,cube_imagePoints.astype(int),axis_cube_img_points)\n",
    "        result_img=draw_axis(result_img,table_imagePoints.astype(int),axis_table_img_points)\n",
    "\n",
    "        # 取得方塊輪廓計算方塊重心位置\n",
    "        contour_outer = detector.get_cube_contour_outer(color)\n",
    "        radius = int(0.04*cv2.arcLength(contour_outer,True))\n",
    "        print(radius)\n",
    "        M = cv2.moments(contour_outer)\n",
    "        if M[\"m00\"] != 0:\n",
    "            centroid_X = int(M[\"m10\"] / M[\"m00\"])# 算形心x\n",
    "            centroid_Y = int(M[\"m01\"] / M[\"m00\"])# 算形心y\n",
    "        # 繪製重心座標點\n",
    "        result_img = cv2.circle(result_img, (centroid_X,centroid_Y),radius, (255,0,255), 2)\n",
    "\n",
    "        # 繪製PNP計算所得座標點\n",
    "        predict_cube_center_imagePoint = cv2.projectPoints(np.float32([x,y,z]),table_rvec,table_tvec,mtx,dist)\n",
    "        predict_cube_center_imagePoint = predict_cube_center_imagePoint[0].astype(np.int16)\n",
    "        \n",
    "        cv2.putText(result_img, f\"{x=:.1f}, {y=:.1f}, {z=:.1f}\", (10,40), cv2.FONT_HERSHEY_SIMPLEX, 1, (128, 0, 128), 2)\n",
    "\n",
    "        # 推算是否位置估計錯誤\n",
    "        if np.linalg.norm(np.array((centroid_X,centroid_Y))-predict_cube_center_imagePoint)>radius:\n",
    "            cv2.putText(result_img, f\"Error\", (10,200), cv2.FONT_HERSHEY_SIMPLEX, 2, (0, 0, 255), 4)\n",
    "            result_img = cv2.circle(result_img, predict_cube_center_imagePoint.ravel(),5, (0,0,255), -1)\n",
    "        else:\n",
    "            cv2.putText(result_img, f\"Ok\", (10,200), cv2.FONT_HERSHEY_SIMPLEX, 2, (0, 255, 0), 4)\n",
    "            result_img = cv2.circle(result_img, predict_cube_center_imagePoint.ravel(),5, (0,255,0), -1)\n",
    "        cv2.imshow(\"result\",result_img)\n",
    "        if cv2.waitKey(1) & 0xFF == ord(\"q\"):\n",
    "            break\n",
    "    else :\n",
    "        break\n",
    "cv2.destroyAllWindows()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
