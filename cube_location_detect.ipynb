{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 照片拍攝，透過opencv拍照"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "\n",
    "cap = cv2.VideoCapture(1,cv2.CAP_DSHOW)\n",
    "\n",
    "num = 0\n",
    "\n",
    "while cap.isOpened():\n",
    "\n",
    "    succes, img = cap.read()\n",
    "\n",
    "    k = cv2.waitKey(5)\n",
    "\n",
    "    if k == ord(\"q\"):\n",
    "        break\n",
    "    elif k == ord('s'): # wait for 's' key to save and exit\n",
    "        cv2.imwrite('images/img' + str(num) + '.png', img)\n",
    "        print(\"image saved!\")\n",
    "        num += 1\n",
    "\n",
    "    cv2.imshow('Img',img)\n",
    "\n",
    "cap.release()\n",
    "\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 繪圖函數宣告"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 繪製函數定義\n",
    "import numpy as np\n",
    "def draw_axis(img, corners, image_points):\n",
    "    corner = tuple(corners[0].ravel())\n",
    "    img = cv2.line(img, corner, tuple(np.int16(image_points[0].ravel())), (255,0,0), 5)\n",
    "    img = cv2.line(img, corner, tuple(np.int16(image_points[1].ravel())), (0,255,0), 5)\n",
    "    img = cv2.line(img, corner, tuple(np.int16(image_points[2].ravel())), (0,0,255), 5)\n",
    "    return img\n",
    "def draw_xy_lines(img, image_points):\n",
    "    img = cv2.line(img, tuple(np.int16(image_points[0].ravel())), tuple(np.int16(image_points[1].ravel())), (0,0,0), 5)\n",
    "    img = cv2.line(img, tuple(np.int16(image_points[1].ravel())), tuple(np.int16(image_points[2].ravel())), (0,0,0), 5)\n",
    "    return img\n",
    "def draw_z_lines(img, image_points):\n",
    "    img = cv2.line(img, tuple(np.int16(image_points[1].ravel())), tuple(np.int16(image_points[3].ravel())), (128,128,0), 5)\n",
    "    return img"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 方塊座標系轉換至桌面座標系"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "模型讀取"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "from ultralytics import YOLO\n",
    "import numpy as np\n",
    "import cube_detector.cube_detector as CD\n",
    "import pickle\n",
    "\n",
    "model = YOLO(\"./yolov8n-seg-custom.pt\")\n",
    "surface_model = YOLO('./cube_surface_seg2.pt')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "方塊到桌面座標系轉換"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 照片計算"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "detector=CD.CubeDetector(model,surface_model)\n",
    "detector\n",
    "with open('test_calibration.pkl', 'rb') as file:\n",
    "    mtx,dist = pickle.load(file)\n",
    "with open('test_table_points.pkl','rb') as file:\n",
    "    table_objectPoints,table_imagePoints = pickle.load(file)\n",
    "with open('test_table_solvePnP.pkl','rb') as file:\n",
    "    table_rvec,table_tvec = pickle.load(file)\n",
    "color = \"green\"\n",
    "img = cv2.imread(\"test.jpg\")\n",
    "height =480\n",
    "scale = height / img.shape[0]\n",
    "img = cv2.resize(img, None, fx=scale, fy=scale, interpolation=cv2.INTER_LINEAR)\n",
    "#  將圖片丟入偵測器進行偵測\n",
    "result_img = detector.detect(img,index=None,color=None)\n",
    "# 讀取抓到的角點座標\n",
    "cube_imagePoints=detector.get_cube_sequence_imagePoints(color)\n",
    "# 依順序定出對應真實世界對應座標\n",
    "cube_objectPoints=np.array([(0,0,0),(0,25,0),(25,25,0),(25,0,0),(25,0,-25),(0,0,-25)])\n",
    "# 如果抓到六個點採用EPNP算法(較準確穩定)，四個點則是一般算法\n",
    "if cube_imagePoints.shape[0]==6:\n",
    "    PnP_success,cube_rvec,cube_tvec = cv2.solvePnP(cube_objectPoints.astype(float),cube_imagePoints,mtx,dist,flags=cv2.SOLVEPNP_EPNP)\n",
    "elif cube_imagePoints.shape[0]==4:\n",
    "    PnP_success,cube_rvec,cube_tvec = cv2.solvePnP(cube_objectPoints[:4].astype(float),cube_imagePoints,mtx,dist)\n",
    "#  若成功計算出來則計算出該方塊相對於桌面座標系的座標位置\n",
    "if PnP_success:\n",
    "    R1, _ = cv2.Rodrigues(cube_rvec) # 創建方塊到相機座標系的旋轉矩陣\n",
    "    R2, _ = cv2.Rodrigues(table_rvec) # 創建桌面到方塊座標系的旋轉矩陣\n",
    "    T1 = np.eye(4) #創建4*4單位矩陣\n",
    "    T2 = np.eye(4) \n",
    "    T1[:3, :3], T1[:3, 3] = R1, cube_tvec.T #  方塊座標系旋轉加平移到相機座標系 轉換矩陣\n",
    "    T2[:3, :3], T2[:3, 3] = R2, table_tvec.T # 桌面座標系旋轉加平移到相機座標系 轉換矩陣\n",
    "    T2=np.linalg.inv(T2) # 取逆矩陣，變成 相譏座標系到桌面座標系 轉換矩陣\n",
    "    transform_matrix = T2 @ T1 # 結合二者，得到方塊座標系到桌面座標系的轉換矩陣\n",
    "    transformed_point = transform_matrix @ np.array([[12.5, 12.5, -12.5, 1]]).T # 傳入方塊正中央座標，即可得到方塊在桌面座標位置了\n",
    "    # 输出结果\n",
    "    print(\"物體在桌面座標系下的座標:\\n\", transformed_point)\n",
    "# xyz座標位置線繪製\n",
    "x,y,z = transformed_point[0:3].flatten()\n",
    "xyz_line_points=np.float32([[0,y,0],[x,y,0],[x,0,0],[x,y,z]]).reshape(-1,3)\n",
    "xyz_line_points_img,_=cv2.projectPoints(xyz_line_points,table_rvec,table_tvec,mtx,dist)\n",
    "result_img = draw_xy_lines(result_img,xyz_line_points_img)\n",
    "result_img = draw_z_lines(result_img,xyz_line_points_img)\n",
    "\n",
    "# xyz座標軸繪製\n",
    "axis = np.float32([[25,0,0], [0,25,0], [0,0,25]]).reshape(-1,3)\n",
    "axis_cube_img_points, _ = cv2.projectPoints(axis, cube_rvec, cube_tvec, mtx, dist)\n",
    "axis_table_img_points, _ = cv2.projectPoints(axis, table_rvec, table_tvec, mtx, dist)\n",
    "result_img=draw_axis(result_img,cube_imagePoints.astype(int),axis_cube_img_points)\n",
    "# result_img=draw_axis(result_img,table_imagePoints.astype(int),axis_table_img_points)\n",
    "\n",
    "# 取得方塊輪廓計算方塊重心位置\n",
    "contour_outer = detector.get_cube_contour_outer(color)\n",
    "radius = int(0.04*cv2.arcLength(contour_outer,True))\n",
    "print(radius)\n",
    "M = cv2.moments(contour_outer)\n",
    "if M[\"m00\"] != 0:\n",
    "    centroid_X = int(M[\"m10\"] / M[\"m00\"])# 算形心x\n",
    "    centroid_Y = int(M[\"m01\"] / M[\"m00\"])# 算形心y\n",
    "# 繪製重心座標點\n",
    "result_img = cv2.circle(result_img, (centroid_X,centroid_Y),radius, (255,0,255), 2)\n",
    "\n",
    "# 繪製PNP計算所得座標點\n",
    "predict_cube_center_imagePoint = cv2.projectPoints(np.float32([x,y,z]),table_rvec,table_tvec,mtx,dist)\n",
    "predict_cube_center_imagePoint = predict_cube_center_imagePoint[0].astype(np.int16)\n",
    "\n",
    "cv2.putText(result_img, f\"{x=:.1f}, {y=:.1f}, {z=:.1f}\", (10,40), cv2.FONT_HERSHEY_SIMPLEX, 1, (128, 0, 128), 2)\n",
    "\n",
    "# 推算是否位置估計錯誤\n",
    "if np.linalg.norm(np.array((centroid_X,centroid_Y))-predict_cube_center_imagePoint)>radius:\n",
    "    cv2.putText(result_img, f\"Error\", (10,200), cv2.FONT_HERSHEY_SIMPLEX, 2, (0, 0, 255), 4)\n",
    "    result_img = cv2.circle(result_img, predict_cube_center_imagePoint.ravel(),5, (0,0,255), -1)\n",
    "else:\n",
    "    cv2.putText(result_img, f\"Ok\", (10,200), cv2.FONT_HERSHEY_SIMPLEX, 2, (0, 255, 0), 4)\n",
    "    result_img = cv2.circle(result_img, predict_cube_center_imagePoint.ravel(),5, (0,255,0), -1)\n",
    "cv2.imshow(\"result\",result_img)\n",
    "cv2.waitKey(0)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 即時偵測主程式"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hand_cam = cv2.VideoCapture(4,cv2.CAP_ANY)\n",
    "fixed_cam = cv2.VideoCapture(2,cv2.CAP_ANY)\n",
    "cam=cv2.VideoCapture(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hand_cam.release()\n",
    "fixed_cam.release()\n",
    "cam.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[       -650        -250         860]\n"
     ]
    }
   ],
   "source": [
    "detector = CD.CubeDetector(model, surface_model)\n",
    "cap = cv2.VideoCapture(1,cv2.CAP_DSHOW)\n",
    "# cap = cv2.VideoCapture(2,cv2.CAP_ANY)\n",
    "# with open(\"test_calibration.pkl\", \"rb\") as file:\n",
    "#     mtx, dist = pickle.load(file)\n",
    "with open(\"./fixedCam_matrix/MultiMatrix_fixed_640_480.npz\",\"rb\") as file:\n",
    "    mtx = np.load(file)[\"camMatrix\"]\n",
    "    dist = np.load(file)[\"distCoef\"]\n",
    "# with open('test_table_points.pkl','rb') as file:\n",
    "    # table_objectPoints,table_imagePoints = pickle.load(file)\n",
    "# with open('test_table_solvePnP.pkl','rb') as file:\n",
    "#     table_rvec,table_tvec = pickle.load(file)\n",
    "fixed_to_table = np.float32(\n",
    "    [[0, 1, 0, -650],\n",
    "     [1, 0, 0, -250],\n",
    "     [0, 0, -1, 860],\n",
    "     [0, 0, 0, 1]]\n",
    ")\n",
    "_, table_rmtx, table_tvec, _, _, _, _  = cv2.decomposeProjectionMatrix(fixed_to_table[0:3,0:])\n",
    "\n",
    "table_rvec, _ = cv2.Rodrigues(table_rmtx)\n",
    "table_tvec = fixed_to_table[0:3,3]\n",
    "print(table_tvec)   \n",
    "\n",
    "color = \"yellow\"\n",
    "while cap.isOpened():\n",
    "    cap_success, frame = cap.read()\n",
    "    if cap_success:\n",
    "        height = 480\n",
    "        scale = height / frame.shape[0]\n",
    "        frame = cv2.resize(frame, None, fx=scale, fy=scale, interpolation=cv2.INTER_LINEAR)\n",
    "        #  將圖片丟入偵測器進行偵測\n",
    "        result_img = detector.detect(frame, index=None, color=None)\n",
    "        # 讀取抓到的角點座標\n",
    "        cube_imagePoints = detector.get_cube_sequence_imagePoints(color)\n",
    "        if cube_imagePoints is None:\n",
    "            cv2.imshow(\"result\", frame)\n",
    "            if cv2.waitKey(1) & 0xFF == ord(\"q\"):\n",
    "                break\n",
    "            continue\n",
    "        # 依順序定出對應真實世界對應座標\n",
    "        cube_objectPoints = np.array(\n",
    "            [(0, 0, 0), (0, 50, 0), (50, 50, 0),\n",
    "             (50, 0, 0), (50, 0, -50), (0, 0, -50)]\n",
    "        )\n",
    "        # 如果抓到六個點採用EPNP算法(較準確穩定)，四個點則是一般算法\n",
    "        if cube_imagePoints.shape[0] == 6:\n",
    "            PnP_success, cube_rvec, cube_tvec = cv2.solvePnP(\n",
    "                cube_objectPoints.astype(float), cube_imagePoints, mtx, dist, flags=cv2.SOLVEPNP_EPNP)\n",
    "        elif cube_imagePoints.shape[0] == 4:\n",
    "            PnP_success, cube_rvec, cube_tvec = cv2.solvePnP(\n",
    "                cube_objectPoints[:4].astype(float), cube_imagePoints, mtx, dist)\n",
    "        #  若成功計算出來則計算出該方塊相對於桌面座標系的座標位置\n",
    "        if PnP_success:\n",
    "            R1, _ = cv2.Rodrigues(cube_rvec)  # 創建方塊到相機座標系的旋轉矩陣\n",
    "            R2, _ = cv2.Rodrigues(table_rvec)  # 創建桌面到方塊座標系的旋轉矩陣\n",
    "            T1 = np.eye(4)  # 創建4*4單位矩陣\n",
    "            T2 = np.eye(4)\n",
    "            T1[:3, :3], T1[:3, 3] = R1, cube_tvec.T  #  方塊座標系旋轉後平移到相機座標系 轉換矩陣\n",
    "            T2[:3, :3], T2[:3, 3] = R2, table_tvec.T  # 桌面座標系旋轉後平移到相機座標系 轉換矩陣\n",
    "            T2 = np.linalg.inv(T2)  # 取逆矩陣，變成 相譏座標系到桌面座標系 轉換矩陣\n",
    "            # fixed_to_table = np.linalg.inv(fixed_to_table)  # 取逆矩陣，變成 相譏座標系到桌面座標系 轉換矩陣\n",
    "            transform_matrix = T2 @ T1  # 結合二者，得到方塊座標系到桌面座標系的轉換矩陣\n",
    "            transformed_point = (transform_matrix @ np.array([[12.5, 12.5, -12.5, 1]]).T)  # 傳入方塊正中央座標，即可得到方塊在桌面座標位置了\n",
    "            # 输出结果\n",
    "            print(\"物體在桌面座標系下的座標:\\n\", transformed_point)\n",
    "        # xyz座標位置線繪製\n",
    "        x, y, z = transformed_point[0:3].flatten()\n",
    "        xyz_line_points = np.float32([[0, y, 0], [x, y, 0], [x, 0, 0], [x, y, z]]).reshape(-1, 3)\n",
    "        xyz_line_points_img, _ = cv2.projectPoints(xyz_line_points, table_rvec, table_tvec, mtx, dist)\n",
    "        result_img = draw_xy_lines(result_img, xyz_line_points_img)\n",
    "        result_img = draw_z_lines(result_img, xyz_line_points_img)\n",
    "\n",
    "        # xyz座標軸繪製\n",
    "        axis = np.float32([[25, 0, 0], [0, 25, 0], [0, 0, 25]]).reshape(-1, 3)\n",
    "        axis_cube_img_points, _ = cv2.projectPoints(axis, cube_rvec, cube_tvec, mtx, dist)\n",
    "        # axis_table_img_points, _ = cv2.projectPoints(axis, table_rvec, table_tvec, mtx, dist)\n",
    "        result_img = draw_axis(result_img, cube_imagePoints.astype(int), axis_cube_img_points)\n",
    "        # result_img = draw_axis(result_img, table_imagePoints.astype(int), axis_table_img_points)\n",
    "\n",
    "        # 取得方塊輪廓計算方塊重心位置\n",
    "        contour_outer = detector.get_cube_contour_outer(color)\n",
    "        radius = int(0.04 * cv2.arcLength(contour_outer, True))\n",
    "        print(radius)\n",
    "        M = cv2.moments(contour_outer)\n",
    "        if M[\"m00\"] != 0:\n",
    "            centroid_X = int(M[\"m10\"] / M[\"m00\"])  # 算形心x\n",
    "            centroid_Y = int(M[\"m01\"] / M[\"m00\"])  # 算形心y\n",
    "        # 繪製重心座標點\n",
    "        result_img = cv2.circle(result_img, (centroid_X, centroid_Y), radius, (255, 0, 255), 2)\n",
    "\n",
    "        # 繪製PNP計算所得座標點\n",
    "        predict_cube_center_imagePoint = cv2.projectPoints(np.float32([x, y, z]), table_rvec, table_tvec, mtx, dist)\n",
    "        predict_cube_center_imagePoint = predict_cube_center_imagePoint[0].astype(np.int16)\n",
    "\n",
    "        cv2.putText(result_img, f\"{x=:.1f}, {y=:.1f}, {z=:.1f}\", (10, 40),\n",
    "                    cv2.FONT_HERSHEY_SIMPLEX, 1, (128, 0, 128), 2,)\n",
    "\n",
    "        # 推算是否位置估計錯誤\n",
    "        if (np.linalg.norm(np.array((centroid_X, centroid_Y)) - predict_cube_center_imagePoint) > radius):\n",
    "            cv2.putText(result_img, f\"Error\", (10, 200), cv2.FONT_HERSHEY_SIMPLEX, 2, (0, 0, 255), 4,)\n",
    "            result_img = cv2.circle(result_img, predict_cube_center_imagePoint.ravel(), 5, (0, 0, 255), -1)\n",
    "        else:\n",
    "            cv2.putText(result_img, f\"Ok\", (10, 200), cv2.FONT_HERSHEY_SIMPLEX, 2, (0, 255, 0), 4,)\n",
    "            result_img = cv2.circle(\n",
    "                result_img, predict_cube_center_imagePoint.ravel(), 5, (0, 255, 0), -1)\n",
    "        cv2.imshow(\"result\", result_img)\n",
    "        if cv2.waitKey(1) & 0xFF == ord(\"q\"):\n",
    "            break\n",
    "    else:\n",
    "        break\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "# with open('test_calibration.pkl', 'rb') as file:\n",
    "#     mtx,dist = pickle.load(file)\n",
    "#     print(mtx,dist)\n",
    "# with open('./hand_matrix/camMatrix.npy', 'rb') as file:\n",
    "#     mtx = np.load(file)\n",
    "#     print(mtx)\n",
    "# with open('./fixedCam_matrix/MultiMatrix_fixed_640_480.npz', 'rb') as file:\n",
    "#     mtx = np.load(file)\n",
    "#     for item in mtx.files:\n",
    "#         print(item)\n",
    "#         print(mtx[item])\n",
    "with open('./Hcam2Grip/Hcam2grip.npz', 'rb') as file:\n",
    "    mtx = np.load(file)\n",
    "    for item in mtx.files:\n",
    "        print(item)\n",
    "        print(mtx[item])\n",
    "target_pos = arm.position @ h_c2g @ pnp @ np.array([[25,25,-25,1]])\n",
    "target_pos[0:3].flatten()\n",
    "arm.move_to([target_pos[0],target_pos[1],600,-180,0,-60])\n",
    "arm.move_to_position([target_pos[0],arm.position[123],600,-180,0,-60])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "m1 = np.array(\n",
    "    [[1, 0, 0, 1],\n",
    "     [0, 1, 0, 2],\n",
    "     [0, 0, 1, 3],\n",
    "     [0, 0, 0, 1]])\n",
    "m2 = np.array(\n",
    "    [[0, 1, 0, 0],\n",
    "     [1, 0, 0, 0],\n",
    "     [0, 0, 1, 0],\n",
    "     [0, 0, 0, 1]])\n",
    "m3 = np.array(\n",
    "    [[2],\n",
    "     [3],\n",
    "     [1],\n",
    "     [1]])\n",
    "m1@m2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "from ultralytics import YOLO\n",
    "\n",
    "# Load the YOLOv8 model\n",
    "model = YOLO('yolov8n-seg-custom.pt')\n",
    "\n",
    "# Open the video file\n",
    "# video_path = \"path/to/your/video/file.mp4\"\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "# Loop through the video frames\n",
    "while cap.isOpened():\n",
    "    # Read a frame from the video\n",
    "    success, frame = cap.read()\n",
    "\n",
    "    if success:\n",
    "        # Run YOLOv8 inference on the frame\n",
    "        results = model(frame)\n",
    "\n",
    "        # Visualize the results on the frame\n",
    "        annotated_frame = results[0].plot()\n",
    "\n",
    "        # Display the annotated frame\n",
    "        cv2.imshow(\"YOLOv8 Inference\", annotated_frame)\n",
    "\n",
    "        # Break the loop if 'q' is pressed\n",
    "        if cv2.waitKey(1) & 0xFF == ord(\"q\"):\n",
    "            break\n",
    "    else:\n",
    "        # Break the loop if the end of the video is reached\n",
    "        break\n",
    "\n",
    "# Release the video capture object and close the display window\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
