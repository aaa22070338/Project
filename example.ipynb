{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 鏡頭校正"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 圖片偵測"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "from ultralytics import YOLO\n",
    "import numpy as np\n",
    "import importlib\n",
    "import cube_detector as CD\n",
    "import cube_detector2 as CD2\n",
    "import pickle\n",
    "\n",
    "model = YOLO(\"yolov8n-seg-custom.pt\")\n",
    "surface_model = YOLO('cube_surface_seg2.pt')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_axis(img, corners, image_points):\n",
    "    corner = tuple(corners[0].ravel())\n",
    "    img = cv2.line(img, corner, tuple(np.intp(image_points[0].ravel())), (255,0,0), 5)\n",
    "    img = cv2.line(img, corner, tuple(np.intp(image_points[1].ravel())), (0,255,0), 5)\n",
    "    img = cv2.line(img, corner, tuple(np.intp(image_points[2].ravel())), (0,0,255), 5)\n",
    "    return img\n",
    "def draw_xy_lines(img, image_points):\n",
    "    img = cv2.line(img, tuple(np.intp(image_points[0].ravel())), tuple(np.intp(image_points[1].ravel())), (0,0,0), 5)\n",
    "    img = cv2.line(img, tuple(np.intp(image_points[1].ravel())), tuple(np.intp(image_points[2].ravel())), (0,0,0), 5)\n",
    "    return img\n",
    "def draw_z_lines(img, image_points):\n",
    "    img = cv2.line(img, tuple(np.intp(image_points[1].ravel())), tuple(np.intp(image_points[3].ravel())), (0,0,255), 5)\n",
    "    # img = cv2.line(img, tuple(np.intp(image_points[1].ravel())), tuple(np.intp(image_points[2].ravel())), (0,0,0), 5)\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "importlib.reload(CD)\n",
    "importlib.reload(CD2)\n",
    "\n",
    "detector=CD.cubeDetector(model,isCudaSupport=False,processing_hegiht=300)\n",
    "detector2=CD2.cubeDetector(model,surface_model,isCudaSupport=False,processing_hegiht=150)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 側鏡頭PNP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 480x640 3 cubes, 115.5ms\n",
      "Speed: 50.3ms preprocess, 115.5ms inference, 29.1ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 7 surfaces, 114.2ms\n",
      "Speed: 16.8ms preprocess, 114.2ms inference, 34.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[352 370]]\n",
      "\n",
      " [[287 368]]]\n",
      "[2]\n",
      "1\n",
      "[1]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 480x640 7 surfaces, 123.5ms\n",
      "Speed: 14.8ms preprocess, 123.5ms inference, 29.7ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[507 305]]\n",
      "\n",
      " [[444 302]]]\n",
      "[1]\n",
      "1\n",
      "[1]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 480x640 7 surfaces, 120.6ms\n",
      "Speed: 16.3ms preprocess, 120.6ms inference, 35.4ms postprocess per image at shape (1, 3, 480, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "物體在桌面座標系下的座標:\n",
      " [[     101.26]\n",
      " [    -14.888]\n",
      " [     84.587]\n",
      " [          1]]\n"
     ]
    }
   ],
   "source": [
    "# img = cv2.imread(\"test1.jpg\")\n",
    "frame = cv2.imread(\"pnp_test_img/img2.png\")\n",
    "detector.isCudaSupport=True\n",
    "height =480\n",
    "scale = height / frame.shape[0]\n",
    "frame = cv2.resize(frame, None, fx=scale, fy=scale, interpolation=cv2.INTER_LINEAR)\n",
    "img2  = detector2.detect(frame,index=None,color=None,show_process_img=True)\n",
    "\n",
    "cube_imagePoints=detector2.get_cube_largest_surface_imagePoints(\"yellow\")\n",
    "\n",
    "cube_objectPoints=np.array([(0,0,0),(0,25,0),(25,25,0),(25,0,0),(25,0,-25),(0,0,-25)])\n",
    "\n",
    "with open('camera/calibration.pkl', 'rb') as file:\n",
    "    mtx,dist = pickle.load(file)\n",
    "with open('table_points.pkl','rb') as file:\n",
    "    table_objectPoints,table_imagePoints = pickle.load(file)\n",
    "with open('table_solvePnP.pkl','rb') as file:\n",
    "    table_rvec,table_tvec = pickle.load(file)\n",
    "# print(cube_imagePoints)\n",
    "PnP_success,cube_rvec,cube_tvec = cv2.solvePnP(cube_objectPoints.astype(float)[:len(cube_imagePoints)],cube_imagePoints,mtx,dist)\n",
    "# ret,table_rvecs,table_tvecs = cv2.solvePnP(table_objectPoints,table_imagePoints,mtx,dist)\n",
    "\n",
    "axis = np.float32([[25,0,0], [0,25,0], [0,0,25]]).reshape(-1,3)\n",
    "axis_cube_img_points, _ = cv2.projectPoints(axis, cube_rvec, cube_tvec, mtx, dist)\n",
    "axis_table_img_points, _ = cv2.projectPoints(axis, table_rvec, table_tvec, mtx, dist)\n",
    "img2=draw_axis(img2,cube_imagePoints.astype(int),axis_cube_img_points)\n",
    "img2=draw_axis(img2,table_imagePoints.astype(int),axis_table_img_points)\n",
    "if PnP_success:\n",
    "    R1, _ = cv2.Rodrigues(cube_rvec)\n",
    "    R2, _ = cv2.Rodrigues(table_rvec)\n",
    "    T1 = np.eye(4) \n",
    "    T2 = np.eye(4) \n",
    "    T1[:3, :3], T1[:3, 3] = R1, cube_tvec.T  # 方塊座標系旋轉加平移到相機座標系\n",
    "    T2[:3, :3], T2[:3, 3] = R2, table_tvec.T # 桌面座標系旋轉加平移到相機座標系\n",
    "    T2=np.linalg.inv(T2) # 取逆矩陣，變成 相譏座標系到桌面座標系\n",
    "    transform_matrix = T2 @ T1  \n",
    "    transformed_point = transform_matrix @ np.array([[12.5, 12.5, -12.5, 1]]).T\n",
    "    # 输出结果\n",
    "    print(\"物體在桌面座標系下的座標:\\n\", transformed_point)\n",
    "\n",
    "x,y = transformed_point[0:2].flatten()\n",
    "xy_line_points=np.float32([[0,y,0],[x,y,0],[x,0,0]]).reshape(-1,3)\n",
    "xy_line_points_img,_=cv2.projectPoints(xy_line_points,table_rvec,table_tvec,mtx,dist)\n",
    "img2 = draw_xy_lines(img2,xy_line_points_img)\n",
    "cv2.imshow(\"test\", img2)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 夾抓鏡頭PNP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 測試"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 鏡頭拍照"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "num = 101\n",
    "\n",
    "while cap.isOpened():\n",
    "\n",
    "    succes, frame = cap.read()\n",
    "\n",
    "    k = cv2.waitKey(5)\n",
    "\n",
    "    if k == ord('q'):\n",
    "        break\n",
    "    elif k == ord('s'): # wait for 's' key to save and exit\n",
    "        cv2.imwrite('pnp_test_img/img' + str(num) + '.png', frame)\n",
    "        # cv2.imwrite('train_img/cube(' + str(num) + ').JPG', frame)\n",
    "        print(\"image saved!\")\n",
    "        num += 1\n",
    "\n",
    "    cv2.imshow('Img',frame)\n",
    "\n",
    "# Release and destroy all windows before termination\n",
    "cap.release()\n",
    "\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 模型測試"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cube_detector2 as CD2\n",
    "# frame = cv2.imread(\"pnp_test_img/img11.png\")\n",
    "frame = cv2.imread(\"test7.jpg\")\n",
    "detector.isCudaSupport=True\n",
    "height =480\n",
    "scale = height / frame.shape[0]\n",
    "frame = cv2.resize(frame, None, fx=scale, fy=scale, interpolation=cv2.INTER_LINEAR)\n",
    "img2  = detector2.detect(frame,index=None,color=None,show_process_img=True)\n",
    "cv2.imshow(\"img2\",img2)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 其他測試"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "A = np.array([[1, 2,0],\n",
    "              [3, 4,0],\n",
    "              [0,0,1]])\n",
    "\n",
    "B = np.array([[1, 0,2],\n",
    "              [0, 1,2],\n",
    "              [0,0,1]])\n",
    "\n",
    "result =  B @A\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## real time test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cap = cv2.VideoCapture(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cap.release()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 實際用"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "with open('camera/calibration.pkl', 'rb') as file:\n",
    "    mtx,dist = pickle.load(file)\n",
    "with open('table_points.pkl','rb') as file:\n",
    "    table_objectPoints,table_imagePoints = pickle.load(file)\n",
    "with open('table_solvePnP.pkl','rb') as file:\n",
    "    table_rvec,table_tvec = pickle.load(file)\n",
    "color = \"green\"\n",
    "while cap.isOpened():\n",
    "    cap_success, frame = cap.read()\n",
    "    if cap_success:\n",
    "        height =480\n",
    "        scale = height / frame.shape[0]\n",
    "        frame = cv2.resize(frame, None, fx=scale, fy=scale, interpolation=cv2.INTER_LINEAR)\n",
    "        img2  = detector2.detect(frame,index=None,color=None,show_process_img=True)\n",
    "\n",
    "        cube_imagePoints=detector2.get_cube_largest_surface_imagePoints(color)\n",
    "        if cube_imagePoints is None:\n",
    "            cv2.imshow(\"result\",frame)\n",
    "            if cv2.waitKey(1) & 0xFF == ord(\"q\"):\n",
    "                break\n",
    "            continue\n",
    "        cube_objectPoints=np.array([(0,0,0),(0,25,0),(25,25,0),(25,0,0)])\n",
    "\n",
    "        try_counter = 0\n",
    "\n",
    "        radius = int(0.04*cv2.arcLength(contour_outer,True))\n",
    "        vector = cube_imagePoints[2,:]-cube_imagePoints[0,:]\n",
    "        unit_vector = vector/np.linalg.norm(vector)\n",
    "\n",
    "        contour_outer =detector2.get_cube_contour_outer(color)\n",
    "        M = cv2.moments(contour_outer)\n",
    "        if M[\"m00\"] != 0:\n",
    "            centroid_X = int(M[\"m10\"] / M[\"m00\"])# 算形心x\n",
    "            centroid_Y = int(M[\"m01\"] / M[\"m00\"])# 算形心y\n",
    "        \n",
    "        is_predict_fail = False\n",
    "        while True:\n",
    "            PnP_success,cube_rvec,cube_tvec = cv2.solvePnP(cube_objectPoints.astype(float),cube_imagePoints,mtx,dist)\n",
    "\n",
    "            if PnP_success:\n",
    "                R1, _ = cv2.Rodrigues(cube_rvec)\n",
    "                R2, _ = cv2.Rodrigues(table_rvec)\n",
    "                T1 = np.eye(4) \n",
    "                T2 = np.eye(4) \n",
    "                T1[:3, :3], T1[:3, 3] = R1, cube_tvec.T  # 方塊座標系旋轉加平移到相機座標系\n",
    "                T2[:3, :3], T2[:3, 3] = R2, table_tvec.T # 桌面座標系旋轉加平移到相機座標系\n",
    "                T2=np.linalg.inv(T2) # 取逆矩陣，變成 相譏座標系到桌面座標系\n",
    "                transform_matrix = T2 @ T1  \n",
    "                transformed_point = transform_matrix @ np.array([[12.5, 12.5, -12.5, 1]]).T\n",
    "                # 输出结果\n",
    "                # print(\"物體在桌面座標系下的座標:\\n\", transformed_point)\n",
    "            \n",
    "            x,y,z = transformed_point[0:3].flatten()\n",
    "            predict_cube_center_imagePoint = cv2.projectPoints(np.float32([x,y,z]),table_rvec,table_tvec,mtx,dist)\n",
    "            predict_cube_center_imagePoint = predict_cube_center_imagePoint[0].astype(np.int16)\n",
    "            if np.any(predict_cube_center_imagePoint>img2.shape[1]):\n",
    "                is_predict_fail = True\n",
    "                print(\"predict fail\")\n",
    "                break\n",
    "            # print(np.linalg.norm(np.array((centroid_X,centroid_Y))-predict_cube_center_imagePoint))\n",
    "            if np.linalg.norm(np.array((centroid_X,centroid_Y))-predict_cube_center_imagePoint)<=radius:\n",
    "                # print(z,\"-------------------------------------------------\")\n",
    "\n",
    "                break\n",
    "            \n",
    "            # 錯誤修正嘗試\n",
    "            pieces = 40\n",
    "            delta = radius/pieces\n",
    "            if np.any(np.isnan(unit_vector)):\n",
    "                is_predict_fail = True\n",
    "                print(\"predict fail\")\n",
    "                break\n",
    "\n",
    "            # print(try_counter,unit_vector)\n",
    "            if try_counter<pieces:\n",
    "                cube_imagePoints[2,:] += delta*unit_vector\n",
    "            elif pieces <=try_counter <2*pieces:\n",
    "                if try_counter == pieces:\n",
    "                    cube_imagePoints[2,:] -= pieces*delta*unit_vector\n",
    "                cube_imagePoints[2,:] -= delta*unit_vector\n",
    "            else:\n",
    "                print(\"Fix fail!!!!!!!!!!!!!!!!!!!\")\n",
    "                break\n",
    "            \n",
    "            try_counter+=1\n",
    "        \n",
    "                # cv2.putText(img2, f\"error\", (10,200), cv2.FONT_HERSHEY_SIMPLEX, 2, (0, 0, 255), 4)\n",
    "        if is_predict_fail:\n",
    "            cv2.imshow(\"result\",frame)\n",
    "            if cv2.waitKey(1) & 0xFF == ord(\"q\"):\n",
    "                break\n",
    "            continue\n",
    "\n",
    "        xy_line_points=np.float32([[0,y,0],[x,y,0],[x,0,0],[x,y,z]]).reshape(-1,3)\n",
    "        xy_line_points_img,_=cv2.projectPoints(xy_line_points,table_rvec,table_tvec,mtx,dist)\n",
    "        img2 = draw_xy_lines(img2,xy_line_points_img)\n",
    "        img2 = draw_z_lines(img2,xy_line_points_img)\n",
    "\n",
    "        axis = np.float32([[25,0,0], [0,25,0], [0,0,25]]).reshape(-1,3)\n",
    "        axis_cube_img_points, _ = cv2.projectPoints(axis, cube_rvec, cube_tvec, mtx, dist)\n",
    "        axis_table_img_points, _ = cv2.projectPoints(axis, table_rvec, table_tvec, mtx, dist)\n",
    "        img2=draw_axis(img2,cube_imagePoints.astype(int),axis_cube_img_points)\n",
    "        img2=draw_axis(img2,table_imagePoints.astype(int),axis_table_img_points)\n",
    "\n",
    "\n",
    "        # cv2.circle(img2, cube_imagePoints[2,:].astype(np.int16).ravel(),radius, (255,255,0), 2)\n",
    "        cv2.circle(img2, (centroid_X,centroid_Y),radius, (255,0,255), 2)\n",
    "        cv2.circle(img2, predict_cube_center_imagePoint.ravel(),5, (255,0,255), -1)\n",
    "        cv2.putText(img2, f\"{predict_cube_center_imagePoint}\", (10,20), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255,0, 255), 2)\n",
    "        cv2.putText(img2, f\"{x=:.1f}, {y=:.1f}, {z=:.1f}\", (10,60), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 0), 2)\n",
    "\n",
    "        if np.linalg.norm(np.array((centroid_X,centroid_Y))-predict_cube_center_imagePoint)>radius:\n",
    "            cv2.putText(img2, f\"error\", (10,200), cv2.FONT_HERSHEY_SIMPLEX, 2, (0, 0, 255), 4)\n",
    "        else:\n",
    "            cv2.putText(img2, f\"fine\", (10,200), cv2.FONT_HERSHEY_SIMPLEX, 2, (0, 255, 0), 4)\n",
    "            cv2.putText(img2, f\"{z=:.1f} {try_counter=}\", (10,300), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 4)\n",
    "            print(f\"{z=}{try_counter=}\")\n",
    "        cv2.imshow(\"result\",img2)\n",
    "        if cv2.waitKey(1) & 0xFF == ord(\"q\"):\n",
    "            break\n",
    "    else :\n",
    "        break\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "points = np.array([[[342,316]], [[403, 315]], [[371 ,370]], [[370 ,338]]]).reshape(4,2)\n",
    "point=np.array([224,448])\n",
    "distances = np.linalg.norm(points - point, axis=1)\n",
    "nearest_index = np.argmin(distances)\n",
    "point = points[nearest_index]\n",
    "print(point)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 報告用"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "with open('camera/calibration.pkl', 'rb') as file:\n",
    "    mtx,dist = pickle.load(file)\n",
    "with open('table_points.pkl','rb') as file:\n",
    "    table_objectPoints,table_imagePoints = pickle.load(file)\n",
    "with open('table_solvePnP.pkl','rb') as file:\n",
    "    table_rvec,table_tvec = pickle.load(file)\n",
    "color = \"green\"\n",
    "while cap.isOpened():\n",
    "    cap_success, frame = cap.read()\n",
    "    if cap_success:\n",
    "        height =480\n",
    "        scale = height / frame.shape[0]\n",
    "        frame = cv2.resize(frame, None, fx=scale, fy=scale, interpolation=cv2.INTER_LINEAR)\n",
    "        img2  = detector2.detect(frame,index=None,color=None,show_process_img=True)\n",
    "\n",
    "        cube_imagePoints=detector2.get_cube_largest_surface_imagePoints(color)\n",
    "        if cube_imagePoints is None:\n",
    "            cv2.imshow(\"result\",frame)\n",
    "            if cv2.waitKey(1) & 0xFF == ord(\"q\"):\n",
    "                break\n",
    "            continue\n",
    "        cube_objectPoints=np.array([(0,0,0),(0,25,0),(25,25,0),(25,0,0)])\n",
    "\n",
    "# print(cube_imagePoints)\n",
    "        PnP_success,cube_rvec,cube_tvec = cv2.solvePnP(cube_objectPoints.astype(float),cube_imagePoints,mtx,dist)\n",
    "# ret,table_rvecs,table_tvecs = cv2.solvePnP(table_objectPoints,table_imagePoints,mtx,dist)\n",
    "\n",
    "\n",
    "        if PnP_success:\n",
    "            R1, _ = cv2.Rodrigues(cube_rvec)\n",
    "            R2, _ = cv2.Rodrigues(table_rvec)\n",
    "            T1 = np.eye(4) \n",
    "            T2 = np.eye(4) \n",
    "            T1[:3, :3], T1[:3, 3] = R1, cube_tvec.T  # 方塊座標系旋轉加平移到相機座標系\n",
    "            T2[:3, :3], T2[:3, 3] = R2, table_tvec.T # 桌面座標系旋轉加平移到相機座標系\n",
    "            T2=np.linalg.inv(T2) # 取逆矩陣，變成 相譏座標系到桌面座標系\n",
    "            transform_matrix = T2 @ T1  \n",
    "            transformed_point = transform_matrix @ np.array([[12.5, 12.5, -12.5, 1]]).T\n",
    "            # 输出结果\n",
    "            print(\"物體在桌面座標系下的座標:\\n\", transformed_point)\n",
    "\n",
    "        x,y,z = transformed_point[0:3].flatten()\n",
    "        xy_line_points=np.float32([[0,y,0],[x,y,0],[x,0,0]]).reshape(-1,3)\n",
    "        xy_line_points_img,_=cv2.projectPoints(xy_line_points,table_rvec,table_tvec,mtx,dist)\n",
    "        img2 = draw_xy_lines(img2,xy_line_points_img)\n",
    "\n",
    "        axis = np.float32([[25,0,0], [0,25,0], [0,0,25]]).reshape(-1,3)\n",
    "        axis_cube_img_points, _ = cv2.projectPoints(axis, cube_rvec, cube_tvec, mtx, dist)\n",
    "        axis_table_img_points, _ = cv2.projectPoints(axis, table_rvec, table_tvec, mtx, dist)\n",
    "        img2=draw_axis(img2,cube_imagePoints.astype(int),axis_cube_img_points)\n",
    "        img2=draw_axis(img2,table_imagePoints.astype(int),axis_table_img_points)\n",
    "\n",
    "        predict_cube_center_imagePoint = cv2.projectPoints(np.float32([x,y,z]),table_rvec,table_tvec,mtx,dist)\n",
    "        predict_cube_center_imagePoint = predict_cube_center_imagePoint[0].astype(np.int16)\n",
    "        \n",
    "        contour_outer =detector2.get_cube_contour_outer(color)\n",
    "        radius = int(0.04*cv2.arcLength(contour_outer,True))\n",
    "        print(radius)\n",
    "        M = cv2.moments(contour_outer)\n",
    "        if M[\"m00\"] != 0:\n",
    "            centroid_X = int(M[\"m10\"] / M[\"m00\"])# 算形心x\n",
    "            centroid_Y = int(M[\"m01\"] / M[\"m00\"])# 算形心y\n",
    "        img2 = cv2.circle(img2, (centroid_X,centroid_Y),radius, (255,0,255), 2)\n",
    "        img2 = cv2.circle(img2, predict_cube_center_imagePoint.ravel(),5, (255,0,255), -1)\n",
    "        cv2.putText(img2, f\"{predict_cube_center_imagePoint}\", (10,20), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255,0, 255), 2)\n",
    "        cv2.putText(img2, f\"{x=:.1f}, {y=:.1f}, {z=:.1f}\", (10,60), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 0), 2)\n",
    "\n",
    "        if np.linalg.norm(np.array((centroid_X,centroid_Y))-predict_cube_center_imagePoint)>radius:\n",
    "            cv2.putText(img2, f\"error\", (10,200), cv2.FONT_HERSHEY_SIMPLEX, 2, (0, 0, 255), 4)\n",
    "        else:\n",
    "            cv2.putText(img2, f\"fine\", (10,200), cv2.FONT_HERSHEY_SIMPLEX, 2, (0, 255, 0), 4)\n",
    "        cv2.imshow(\"result\",img2)\n",
    "        if cv2.waitKey(1) & 0xFF == ord(\"q\"):\n",
    "            break\n",
    "    else :\n",
    "        break\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "from ultralytics import YOLO\n",
    "\n",
    "# Load the YOLOv8 model\n",
    "model = YOLO('cube_surface_seg2.pt')\n",
    "\n",
    "# Open the video file\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "# Loop through the video frames\n",
    "while cap.isOpened():\n",
    "    # Read a frame from the video\n",
    "    PnP_success, frame = cap.read()\n",
    "\n",
    "    if PnP_success:\n",
    "        # Run YOLOv8 inference on the frame\n",
    "        results = model(frame)\n",
    "\n",
    "        # Visualize the results on the frame\n",
    "        annotated_frame = results[0].plot()\n",
    "\n",
    "        # Display the annotated frame\n",
    "        cv2.imshow(\"YOLOv8 Inference\", annotated_frame)\n",
    "\n",
    "        # Break the loop if 'q' is pressed\n",
    "        if cv2.waitKey(1) & 0xFF == ord(\"q\"):\n",
    "            break\n",
    "    else:\n",
    "        # Break the loop if the end of the video is reached\n",
    "        break\n",
    "\n",
    "# Release the video capture object and close the display window\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ultralytics import YOLO\n",
    "model = YOLO(\"cube_surface_seg.pt\")\n",
    "img = cv2.imread(\"pnp_test_img/img2.png\")\n",
    "# 定义要添加的边框大小（以像素为单位）\n",
    "height =480\n",
    "scale = height / img.shape[0]\n",
    "img = cv2.resize(img, None, fx=scale, fy=scale, interpolation=cv2.INTER_LINEAR) \n",
    "\n",
    "result = model.predict(img)\n",
    "for r in result:\n",
    "    print(r.probs.top5)\n",
    "# print(result[0].cpu()[0])\n",
    "values=[]\n",
    "for mask in result[0].masks:\n",
    "    test_value = np.array((mask.xyn))\n",
    "    test_value[:,:,0]=test_value[:,:,0]*img.shape[1]\n",
    "    test_value[:,:,1]=test_value[:,:,1]*img.shape[0]\n",
    "    values.append(test_value.astype(int))\n",
    "mask = np.zeros((img.shape[0],img.shape[1]), dtype=np.uint8)\n",
    "mask = cv2.drawContours(mask,values,-1, 255, 1)\n",
    "# print(test_value)\n",
    "# img2 = result[0].plot()\n",
    "cv2.imshow(\"img2\",mask)\n",
    "\n",
    "\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 找桌面座標"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## V1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "\n",
    "# 创建一个空白图像\n",
    "\n",
    "image = cv2.imread('pnp_test_img/img0.png')  # 替换为您的图像文件路径\n",
    "\n",
    "drawing_image= image.copy()\n",
    "Adjusted_image= None\n",
    "\n",
    "isAdjusting=False\n",
    "isDrawing = True  # 标记是否正在绘制线段\n",
    "isFirstDraw=True\n",
    "square_image_points = []\n",
    "line_thickness=2\n",
    "# 回调函数，用于处理鼠标事件\n",
    "def draw_line(event, x, y, flags, param):\n",
    "    global  isDrawing,drawing_image,Adjusted_image,square_image_points,isAdjusting,isFirstDraw,line_thickness\n",
    "    if event == cv2.EVENT_LBUTTONDOWN:  # 鼠标左键按下事件\n",
    "        if isDrawing:\n",
    "            if isFirstDraw:\n",
    "                isFirstDraw = False\n",
    "            else :\n",
    "                cv2.line(drawing_image,square_image_points[-1],(x,y),(255,0,0),2)\n",
    "            if len(square_image_points) < 4:\n",
    "                square_image_points.append((x,y))\n",
    "            if len(square_image_points)==4:\n",
    "                isDrawing = False\n",
    "                isAdjusting = True\n",
    "                Adjusted_image=image.copy()\n",
    "                cv2.polylines(Adjusted_image, [np.array(square_image_points)], isClosed=True, color=(0, 255, 0), thickness=2)\n",
    "                \n",
    "        elif isAdjusting:\n",
    "            distances = np.linalg.norm(np.array(square_image_points) - np.array((x,y)), axis=1)\n",
    "            nearest_index = np.argmin(distances)\n",
    "            square_image_points[nearest_index]=(x,y)\n",
    "            Adjusted_image=image.copy()\n",
    "            cv2.polylines(Adjusted_image, [np.array(square_image_points)], isClosed=True, color=(0, 255, 0), thickness=2)\n",
    "    elif event == cv2.EVENT_MOUSEMOVE:  # 鼠标移动事件\n",
    "        if isDrawing and not isFirstDraw:\n",
    "            temp_image = drawing_image.copy()  # 复制图像以防止绘制覆盖\n",
    "            cv2.line(temp_image, square_image_points[-1], (x, y), (0, 255, 0), line_thickness)\n",
    "            cv2.imshow('Set Table axis', temp_image)\n",
    "        if isAdjusting:\n",
    "            cv2.imshow('Set Table axis', Adjusted_image)\n",
    "\n",
    "\n",
    "# 创建一个窗口并将鼠标事件处理函数绑定到它\n",
    "cv2.namedWindow('Set Table axis')\n",
    "cv2.setMouseCallback('Set Table axis', draw_line)\n",
    "# 在窗口中显示图像，并等待用户按下ESC键退出\n",
    "while True:\n",
    "    if not isAdjusting:\n",
    "        cv2.imshow('Set Table axis', drawing_image)\n",
    "    else:\n",
    "        cv2.imshow('Set Table axis', Adjusted_image)\n",
    "    key = cv2.waitKey(1)\n",
    "    if key == 27:  # 如果按下ESC键，退出循环\n",
    "        break\n",
    "   \n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "\n",
    "with open('table_points.pkl', 'wb') as file:\n",
    "        pickle.dump((np.float32([(0,0),(custom_width,0),(custom_height,custom_width),(0,custom_height)]),\n",
    "                     np.float32(square_image_points)), file)\n",
    "\n",
    "# with open('table_points.pkl', 'rb') as file:\n",
    "#     img_points,object_points = pickle.load(file)\n",
    "#     print(img_points)\n",
    "#     print(object_points)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# V2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#超屌抓桌面程式\n",
    "\n",
    "\n",
    "import cv2\n",
    "\n",
    "#讀取寬高參數\n",
    "square_height,square_width = setHeightWin()\n",
    "square_object_points=np.float32([(0,0,0),(square_width,0,0),(square_width,square_height,0),(0,square_height,0)])\n",
    "\n",
    "with open('camera/calibration.pkl', 'rb') as file:\n",
    "    mtx,dist = pickle.load(file)\n",
    "\n",
    "image = cv2.imread('pnp_test_img/img101.png')  # 載入圖片\n",
    "\n",
    "drawing_image = image.copy()\n",
    "Adjusted_image = None \n",
    "\n",
    "isDrawing = True\n",
    "isAdjusting = False\n",
    "isFirstDraw = True\n",
    "square_image_points = []\n",
    "line_thickness = 2\n",
    "# 回調函數，處理滑鼠事件\n",
    "def draw_line(event, x, y, flags, param):\n",
    "    global line_start, line_end, isDrawing,drawing_image,Adjusted_image,square_image_points,isAdjusting,isFirstDraw,line_thickness\n",
    "    #偵測事件\n",
    "    if event == cv2.EVENT_LBUTTONDOWN:  # 當按下左鍵\n",
    "        if isDrawing:\n",
    "            if isFirstDraw:\n",
    "                isFirstDraw = False\n",
    "            else :\n",
    "                cv2.line(drawing_image,square_image_points[-1],(x,y),(255,0,0),line_thickness)\n",
    "            if len(square_image_points) < 4:\n",
    "                square_image_points.append((x,y))\n",
    "            if len(square_image_points)==4:\n",
    "                isDrawing = False\n",
    "                isAdjusting = True\n",
    "                frame_update()\n",
    "        elif isAdjusting:\n",
    "            distances = np.linalg.norm(np.array(square_image_points) - np.array((x,y)), axis=1)\n",
    "            nearest_index = np.argmin(distances)\n",
    "            square_image_points[nearest_index]=(x,y)\n",
    "            frame_update()\n",
    "    elif event == cv2.EVENT_MOUSEMOVE:  # 當滑鼠移動\n",
    "        if isDrawing and not isFirstDraw:\n",
    "            temp_image = drawing_image.copy()  # 複製圖像而非變更原圖\n",
    "            cv2.line(temp_image, square_image_points[-1], (x, y), (0, 255, 0), line_thickness)\n",
    "            cv2.imshow('Set Table axis', temp_image)\n",
    "        if isAdjusting:\n",
    "            cv2.imshow('Set Table axis', Adjusted_image)\n",
    "\n",
    "    elif event == cv2.EVENT_MOUSEWHEEL: # 當滑鼠滾輪滾動\n",
    "        delta = flags\n",
    "        if delta > 0:\n",
    "            if line_thickness==3:\n",
    "                pass\n",
    "            else:\n",
    "                line_thickness+=1\n",
    "        elif delta < 0:\n",
    "            if line_thickness == 1:\n",
    "                pass\n",
    "            else:\n",
    "                line_thickness-=1\n",
    "        frame_update()\n",
    "\n",
    "# 創建視窗\n",
    "cv2.namedWindow('Set Table axis')\n",
    "# 綁定監聽滑鼠事件，綁定處理事件回調函數\n",
    "cv2.setMouseCallback('Set Table axis', draw_line)\n",
    "\n",
    "def frame_update(): # 進行畫面更新\n",
    "    global Adjusted_image, square_image_points,line_thickness,rvecs,tvecs\n",
    "    Adjusted_image=image.copy()\n",
    "    cv2.polylines(Adjusted_image, [np.array(square_image_points)], isClosed=True, color=(0, 255, 0), thickness=line_thickness)\n",
    "    for coordinate,point in zip(square_object_points,square_image_points):\n",
    "        cv2.putText(Adjusted_image, f\"{list(coordinate)}\", point, cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255,0, 255), 2)\n",
    "    square_img_points = np.float32(square_image_points)\n",
    "    # print(square_img_points)\n",
    "    ret,rvecs,tvecs = cv2.solvePnP(square_object_points,square_img_points,mtx,dist)\n",
    "    # print(rvecs)\n",
    "    axis = np.float32([[100,0,0], [0,100,0], [0,0,100]]).reshape(-1,3)\n",
    "    axis_img_points, _ = cv2.projectPoints(axis, rvecs, tvecs, mtx, dist)\n",
    "    draw_axis(Adjusted_image,square_img_points.astype(int),axis_img_points)\n",
    "\n",
    "# 顯示圖像\n",
    "while True:\n",
    "    if not isAdjusting:\n",
    "        cv2.imshow('Set Table axis', drawing_image)\n",
    "    else:\n",
    "        cv2.imshow('Set Table axis', Adjusted_image)\n",
    "    key = cv2.waitKey(1)\n",
    "    if key == 27:  # 當按下ESC退出循環\n",
    "        break\n",
    "    if len(square_image_points)!=4: #確認是否四個像素座標點抓到了\n",
    "        continue\n",
    "    if key == ord(\"r\"): # Z軸對調\n",
    "        square_image_points[1],square_image_points[3]=square_image_points[3],square_image_points[1]\n",
    "        # square_coordinates[1],square_coordinates[3]=square_coordinates[3],square_coordinates[1]\n",
    "        frame_update()\n",
    "    if key == ord(\"e\"): # 變更原點\n",
    "        square_image_points=square_image_points[-1:]+ square_image_points[:-1] #前包後不包\n",
    "        frame_update()\n",
    "    if key == ord(\"w\"): # 重設長寬\n",
    "        square_height,square_width = setHeightWin()\n",
    "        square_object_points=np.float32([(0,0,0),(square_width,0,0),(square_width,square_height,0),(0,square_height,0)])\n",
    "        frame_update()\n",
    "    if key ==ord(\"q\"): # 長寬互換\n",
    "        square_height,square_width=square_width,square_height\n",
    "        square_object_points=np.float32([(0,0,0),(square_width,0,0),(square_width,square_height,0),(0,square_height,0)])\n",
    "        frame_update()\n",
    "    if key == ord(\"s\"): # 儲存真實與圖像座標和PNP計算結果\n",
    "        with open('table_points.pkl', 'wb') as file:\n",
    "                pickle.dump((square_object_points,np.float32(square_image_points)), file)\n",
    "        with open('table_solvePnP.pkl', 'wb') as file:\n",
    "                pickle.dump((rvecs,tvecs), file)\n",
    "        print(\"saved\")\n",
    "                    \n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tkinter as tk\n",
    "\n",
    "# 創建獲取長寬表單視窗\n",
    "def setHeightWin():\n",
    "    root = tk.Tk()\n",
    "    root.title(\"Input Form\")\n",
    "\n",
    "    # 獲取螢幕寬高\n",
    "    screen_width = root.winfo_screenwidth()\n",
    "    screen_height = root.winfo_screenheight()\n",
    "\n",
    "    # 設置視窗寬高(像素)\n",
    "    window_width = 400  \n",
    "    window_height = 150 \n",
    "\n",
    "    # 計算視窗左上角座標\n",
    "    x = (screen_width - window_width) // 2\n",
    "    y = (screen_height - window_height) // 2\n",
    "\n",
    "    # 視窗生成\n",
    "    root.geometry(f\"{window_width}x{window_height}+{x}+{y}\")\n",
    "\n",
    "    # 創建label, entry元件顯示讀取參數\n",
    "    label_height = tk.Label(root, text=\"Height:\", font=(\"Helvetica\", 14))\n",
    "    label_height.pack()\n",
    "\n",
    "    entry_height = tk.Entry(root, font=(\"Helvetica\", 14),justify=\"center\")\n",
    "    entry_height.pack()\n",
    "\n",
    "    label_width = tk.Label(root, text=\"Width:\", font=(\"Helvetica\", 14))\n",
    "    label_width.pack()\n",
    "\n",
    "    entry_width = tk.Entry(root, font=(\"Helvetica\", 14),justify=\"center\")\n",
    "    entry_width.pack()\n",
    "    \n",
    "    result = []\n",
    "    # 處理送出的表單\n",
    "    def submit_form():\n",
    "        height = entry_height.get()\n",
    "        width = entry_width.get()\n",
    "        result.extend([height, width])\n",
    "\n",
    "        if any(item == \"\" for item in result):# 當缺少參數的時候就將參數清空，不採取動作\n",
    "            result.clear()\n",
    "            return\n",
    "        # 參數沒問題就銷毀視窗，回傳數值\n",
    "        root.destroy()\n",
    "    # 將enter綁定送出表單\n",
    "    root.bind('<Return>', lambda event=None: submit_form())\n",
    "    # 創建\"送出\"按鈕\n",
    "    submit_button = tk.Button(root, text=\"送出\", command=submit_form,width=10,height=1,font=(\"Helveticsa\",14))\n",
    "    submit_button.pack()\n",
    "\n",
    "    # 啟動Tkinter主循環\n",
    "    root.mainloop()\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
