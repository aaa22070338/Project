{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "from ultralytics import YOLO\n",
    "import numpy as np\n",
    "import cv2\n",
    "import pickle\n",
    "import catcher as CT\n",
    "import torch\n",
    "import SaveSystem_by_grip\n",
    "import SaveSystem_by_environment\n",
    "\n",
    "print(torch.cuda.is_available())\n",
    "Save_2_grip = SaveSystem_by_grip.save_system()\n",
    "Save_2_environ = SaveSystem_by_environment.save_system()\n",
    "\n",
    "surface_model = YOLO(\"cube_surface_seg2.pt\")\n",
    "cube_model = YOLO(\"yolov8n-seg-custom.pt\")\n",
    "\n",
    "with open('./hand_matrix/calibration.pkl', 'rb') as file:\n",
    "    camera_matrix, dist_coeff = pickle.load(file)\n",
    "# print(camera_matrix, dist_coeff)\n",
    "# with open('./hand_matrix/camMatrix.npy', 'rb') as file:\n",
    "#     m_camera_matrix = np.load(file)\n",
    "# with open('./hand_matrix/distCoef.npy', 'rb') as file:\n",
    "#     m_dist_coeff = np.load(file)\n",
    "# print(m_camera_matrix, m_dist_coeff)\n",
    "    \n",
    "CT = CT.block_detect(surface_model=surface_model, cube_model=cube_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#HSV\n",
    "import cv2\n",
    "def empty(v):\n",
    "    pass\n",
    "\n",
    "block = cv2.imread('./images/img5.png')\n",
    "block = cv2.resize(block, (0, 0), fx=.7, fy=.7)\n",
    "\n",
    "cv2.namedWindow('TrackBar')\n",
    "cv2.resizeWindow('TrackBar', 640, 320)\n",
    "\n",
    "cv2.createTrackbar('Hue Min', 'TrackBar', 0, 179, empty)\n",
    "cv2.createTrackbar('Hue Max', 'TrackBar', 179, 179, empty)\n",
    "cv2.createTrackbar('Sat Min', 'TrackBar', 0, 255, empty)\n",
    "cv2.createTrackbar('Sat Max', 'TrackBar', 255, 255, empty)\n",
    "cv2.createTrackbar('Val Min', 'TrackBar', 0, 255, empty)\n",
    "cv2.createTrackbar('Val Max', 'TrackBar', 255, 255, empty)\n",
    "\n",
    "hsv = cv2.cvtColor(block,cv2.COLOR_BGR2HSV)\n",
    "while True:\n",
    "    h_min = cv2.getTrackbarPos('Hue Min', 'TrackBar')\n",
    "    h_max = cv2.getTrackbarPos('Hue Max', 'TrackBar')\n",
    "    s_min = cv2.getTrackbarPos('Sat Min', 'TrackBar')\n",
    "    s_max = cv2.getTrackbarPos('Sat Max', 'TrackBar')\n",
    "    v_min = cv2.getTrackbarPos('Val Min', 'TrackBar')\n",
    "    v_max = cv2.getTrackbarPos('Val Max', 'TrackBar')\n",
    "    # print(h_min, h_max, s_min, s_max, v_min, v_max)\n",
    "    \n",
    "    lower = np.array([h_min, s_min, v_min])\n",
    "    upper = np.array([h_max, s_max, v_max])\n",
    "    \n",
    "    mask = cv2.inRange(hsv, lower, upper)\n",
    "    result = cv2.bitwise_and(block, block, mask=mask)\n",
    "\n",
    "    cv2.imshow('block', block)\n",
    "    # cv2.imshow('hsv', hsv)\n",
    "    cv2.imshow('mask', mask)\n",
    "    cv2.imshow('result', result)\n",
    "    \n",
    "\n",
    "    key = cv2.waitKey(1)\n",
    "    if key == 27:\n",
    "        break\n",
    "\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hsv_boundary = {\n",
    "    \"red\": np.array([[0, 150, 0], [20, 255, 255]], dtype=np.uint8),\n",
    "    \"blue\": np.array([[0, 0, 0], [179, 70, 80]], dtype=np.uint8),\n",
    "    \"green\": np.array([[38, 33, 0], [75, 165, 255]], dtype=np.uint8),\n",
    "    \"yellow\": np.array([[20, 50, 110], [50, 255, 255]], dtype=np.uint8),\n",
    "    \"purple\": np.array([[100, 0, 55], [160, 255, 160]], dtype=np.uint8)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#抓圖片\n",
    "img = cv2.imread(\"paper.jpg\")\n",
    "# img = cv2.imread(\"123.jpg\")\n",
    "# img = cv2.resize(img, (640, 480))\n",
    "\n",
    "object_points = np.array([\n",
    "    [0,0,0],#1\n",
    "    [0,25,0],#2\n",
    "    [25,25,0],#3\n",
    "    [25,0,0],#4\n",
    "    [0,0,25],#5\n",
    "    [0,25,25],#6\n",
    "    [25,25,25],#7\n",
    "    [25,0,25],#8\n",
    "], dtype=np.float32)\n",
    "SS.reset()\n",
    "text_offset = 0\n",
    "\n",
    "# text_img = np.zeros((img.shape[0], img.shape[1], 3), dtype=np.uint8)\n",
    "for image_points in CT.detect_parts(img, 2):\n",
    "    # image_points = np.array(image_points, dtype=np.float32)\n",
    "    for color_name, rgb in CT.get_color_text(img):\n",
    "        image_points = np.float32(image_points)\n",
    "        retval, rvec, tvec = cv2.solvePnP(object_points[:4], image_points, camera_matrix, dist_coeff)\n",
    "        x = tvec[0]\n",
    "        y = tvec[1]\n",
    "        z = tvec[2]\n",
    "        rotation_matrix, _ = cv2.Rodrigues(rvec)\n",
    "        # 使用旋转矩阵计算欧拉角（roll-pitch-yaw 顺序）\n",
    "        yaw = np.arctan2(rotation_matrix[1, 0], rotation_matrix[0, 0])\n",
    "        pitch = np.arctan2(\n",
    "            -rotation_matrix[2, 0],\n",
    "            np.sqrt(rotation_matrix[2, 1] ** 2 + rotation_matrix[2, 2] ** 2),\n",
    "        )\n",
    "        roll = np.arctan2(rotation_matrix[2, 1], rotation_matrix[2, 2])\n",
    "        # 将弧度转换为度数\n",
    "        rz = np.degrees(yaw)\n",
    "        ry = np.degrees(pitch)\n",
    "        rx = np.degrees(roll)\n",
    "        RotationZ = np.array([rz])\n",
    "        text_loc_tvec = (5, 15 )\n",
    "        text_loc_rvec = (5, 32 )\n",
    "        text_loc_check = (400, 15 )\n",
    "        # print(color_name)\n",
    "        print(f\"{x=}\")\n",
    "        print(f\"{y=}\")\n",
    "        print(f\"{rx=}\")\n",
    "        Save_2_environ.save_coordinate(color_name, x, y, RotationZ, 10)\n",
    "        xyz_str = [f\"{c}: {v[0]:.2f}\" for c, v in zip(\"xyz\", [x, y, z])]\n",
    "        cv2.putText(img, f\"{color_name} {', '.join(xyz_str)}\", text_loc_tvec, cv2.FONT_HERSHEY_SIMPLEX, 0.5, rgb, 2)\n",
    "        cv2.putText(img, f\"Rotate Z: {rz:.1f},   Rotate Y: {ry:.1f},   Rotate X: {rx:.1f}\", text_loc_rvec, cv2.FONT_HERSHEY_SIMPLEX, 0.5, rgb, 2)\n",
    "        if -10 < x < 10 and -10 < y < 10:\n",
    "            cv2.putText(img, \"OK\", text_loc_check, cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 2)\n",
    "        else:\n",
    "            cv2.putText(img, \"Moving\", text_loc_check, cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 0, 255) ,2)\n",
    "        cv2.circle(img, (int(x[0]), int(y[0])), 5, (0, 0, 255), -1)\n",
    "\n",
    "cv2.imshow('img', img)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.spatial.transform import Rotation as R\n",
    "\n",
    "def transform_matrix(x, y, z, rx, ry, rz):\n",
    "    # 轉換為弧度\n",
    "    rx, ry, rz = np.radians(rx), np.radians(ry), np.radians(rz)\n",
    "\n",
    "    # 計算旋轉矩陣\n",
    "    rotation_matrix = R.from_euler('xyz', [rx, ry, rz], degrees=False).as_matrix()\n",
    "\n",
    "    # 構建轉移矩陣\n",
    "    transformation_matrix = np.vstack([np.hstack([rotation_matrix, np.array([[x], [y], [z]])]),\n",
    "                                      np.array([0, 0, 0, 1])])\n",
    "\n",
    "    return transformation_matrix\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def rotation_x(theta):\n",
    "    return np.array([[1, 0, 0],\n",
    "                     [0, np.cos(theta), -np.sin(theta)],\n",
    "                     [0, np.sin(theta), np.cos(theta)]])\n",
    "\n",
    "def rotation_y(theta):\n",
    "    return np.array([[np.cos(theta), 0, np.sin(theta)],\n",
    "                     [0, 1, 0],\n",
    "                     [-np.sin(theta), 0, np.cos(theta)]])\n",
    "\n",
    "def rotation_z(theta):\n",
    "    return np.array([[np.cos(theta), -np.sin(theta), 0],\n",
    "                     [np.sin(theta), np.cos(theta), 0],\n",
    "                     [0, 0, 1]])\n",
    "\n",
    "def transform_matrix(x, y, z, rx, ry, rz):\n",
    "    rx = np.radians(rx)\n",
    "    ry = np.radians(ry)\n",
    "    rz = np.radians(rz)\n",
    "\n",
    "    rotation_matrix = np.dot(rotation_z(rz), np.dot(rotation_y(ry), rotation_x(rx)))\n",
    "    translation_vector = np.array([[x], [y], [z]])\n",
    "\n",
    "# 合併旋轉矩陣和平移向量\n",
    "    transformation_matrix = np.vstack([np.hstack([rotation_matrix, translation_vector]),\n",
    "                                      np.array([0, 0, 0, 1])])\n",
    "\n",
    "    return transformation_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "lens = cv2.VideoCapture(0,cv2.CAP_DSHOW)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "lens.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# object_points = np.array([\n",
    "#     [-12.5,-12.5,0],#1\n",
    "#     [-12.5,12.5,0],#2\n",
    "#     [12.5,12.5,0],#3\n",
    "    # [12.5,-12.5,0],#4\n",
    "# ], dtype=np.float32)\n",
    "object_points = np.array( #中心\n",
    "    [\n",
    "        [-25, -25, 0],  # 1\n",
    "        [-25, 25, 0],  # 2\n",
    "        [25, 25, 0],  # 3\n",
    "        [25, -25, 0],  # 4\n",
    "    ],\n",
    "    dtype=np.float32,\n",
    ")\n",
    "# object_points = np.array([\n",
    "#     [-12.5,-12.5,0],#1\n",
    "#     [-12.5,12.5,0],#2\n",
    "#     [12.5,12.5,0],#3\n",
    "#     [12.5,-12.5,0],#4\n",
    "# ], dtype=np.float32)\n",
    "object_points = np.array(\n",
    "    [\n",
    "        [-25, -25, 0],  # 1\n",
    "        [-25, 25, 0],  # 2\n",
    "        [25, 25, 0],  # 3\n",
    "        [25, -25, 0],  # 4\n",
    "    ],\n",
    "    dtype=np.float32,\n",
    ")\n",
    "Save_2_grip.reset()\n",
    "offset_x = 0\n",
    "offset_y = 0\n",
    "\n",
    "while True:\n",
    "    ret, img = lens.read()\n",
    "    if not ret:\n",
    "        break\n",
    "    vertical_offset = 0\n",
    "    for image_points in CT.detect_parts(img):\n",
    "        for color_name, rgb in CT.get_color_text(img):\n",
    "            image_points = np.float32(image_points)\n",
    "            retval, rvec, tvec = cv2.solvePnP(object_points[:4], image_points, camera_matrix, dist_coeff)\n",
    "            if not retval:\n",
    "                break\n",
    "            x = tvec[0] - offset_x\n",
    "            y = tvec[1] - offset_y\n",
    "            z = tvec[2]\n",
    "            rotation_matrix, _ = cv2.Rodrigues(rvec)\n",
    "            # 使用旋转矩阵计算欧拉角（roll-pitch-yaw 顺序）\n",
    "            yaw = np.arctan2(rotation_matrix[1, 0], rotation_matrix[0, 0])\n",
    "            pitch = np.arctan2(-rotation_matrix[2, 0],np.sqrt(rotation_matrix[2, 1] ** 2 + rotation_matrix[2, 2] ** 2))\n",
    "            roll = np.arctan2(rotation_matrix[2, 1], rotation_matrix[2, 2])\n",
    "            # 将弧度转换为度数\n",
    "            rz = np.degrees(yaw)\n",
    "            ry = np.degrees(pitch)\n",
    "            rx = np.degrees(roll)\n",
    "            RotationZ = np.array([rz])\n",
    "            text_loc_tvec = (5, 15 + vertical_offset)\n",
    "            text_loc_rvec = (5, 32 + vertical_offset)\n",
    "            text_loc_check = (400, 15 + vertical_offset)\n",
    "\n",
    "            Save_2_grip.save_coordinate_by_color(color_name, x, y,RotationZ, 10)\n",
    "            xyz_str = [f\"{c}: {v[0]:.2f}\" for c, v in zip(\"xyz\", [x, y, z])]\n",
    "            cv2.putText(img, f\"{color_name} {', '.join(xyz_str)}\", text_loc_tvec, cv2.FONT_HERSHEY_SIMPLEX, 0.5, rgb, 2)\n",
    "            cv2.putText(img, f\"Rotate Z: {rz:.1f},   Rotate Y: {ry:.1f},   Rotate X: {rx:.1f}\", text_loc_rvec, cv2.FONT_HERSHEY_SIMPLEX, 0.5, rgb, 2)\n",
    "            if -10 < x < 10 and -10 < y < 10:\n",
    "                cv2.putText(img, \"OK\", text_loc_check, cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 2)\n",
    "            else:\n",
    "                cv2.putText(img, \"Moving\", text_loc_check, cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 0, 255) ,2)\n",
    "            vertical_offset += 34\n",
    "            cv2.circle(img, (int(x[0]), int(y[0])), 5, (0, 0, 255), -1)\n",
    "\n",
    "    else:\n",
    "        pass\n",
    "    cv2.imshow(\"test\", img)\n",
    "    key = cv2.waitKey(1)\n",
    "    if key == 27:\n",
    "        break\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.spatial.transform import Rotation as R\n",
    "\n",
    "\n",
    "def calculate_transform_matrix(initial_position, final_position):\n",
    "    # 初始座標和移動後的座標\n",
    "    p1 = np.array(initial_position)\n",
    "    p2 = np.array(final_position)\n",
    "\n",
    "    # 計算平移向量\n",
    "    translation_vector = p2 - p1\n",
    "\n",
    "    # 計算旋轉矩陣\n",
    "    direction = p2 - p1\n",
    "    axis = np.cross(np.array([1, 0, 0]), direction)\n",
    "    angle = np.arccos(np.dot(np.array([1, 0, 0]), direction) / (np.linalg.norm(direction)))\n",
    "\n",
    "    rotation_matrix = R.from_rotvec(axis * angle).as_matrix()\n",
    "\n",
    "    # 構建轉移矩陣\n",
    "    transformation_matrix = np.vstack([np.hstack([rotation_matrix, translation_vector.reshape(3, 1)]),\n",
    "                                      np.array([0, 0, 0, 1])])\n",
    "\n",
    "    return transformation_matrix\n",
    "np.linalg.inv(transform_matrix(200,500,509,-180, 0, -60)) @ calculate_transform_matrix([0,0,509],[200,500,509])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coordinates = Save_2_grip.get_coordinates_by_color([\"green\", \"purple\"])\n",
    "for i in range(0, len(coordinates), 1):\n",
    "    x = coordinates[i][0]\n",
    "    y = coordinates[i][1]\n",
    "    rx = coordinates[i][2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ultralytics import YOLO\n",
    "import robot.robot as bot\n",
    "import socket\n",
    "import pickle\n",
    "import cv2\n",
    "import numpy as np\n",
    "import catcher as CT\n",
    "import cube_detector.cube_detector as CD\n",
    "import SaveSystem_by_environment\n",
    "import SaveSystem_by_grip\n",
    "\n",
    "model_part = YOLO(\"./cube_surface.pt\")\n",
    "model_region = YOLO(\"./cube.pt\")\n",
    "\n",
    "model = YOLO(\"./cube.pt\")\n",
    "surface_model = YOLO('./cube_surface.pt')\n",
    "model_color = YOLO('./cube_color.pt')\n",
    "\n",
    "with open('./hand_matrix/calibration.pkl', 'rb') as file:\n",
    "    camera_matrix, dist_coeff = pickle.load(file)\n",
    "with open(\"./fixedCam_matrix/MultiMatrix_fixed_640_480.npz\",\"rb\") as file:\n",
    "    mtx = np.load(file)[\"camMatrix\"]\n",
    "    dist = np.load(file)[\"distCoef\"]\n",
    "\n",
    "CT = CT.block_detect(model_part, model_region)\n",
    "detector = CD.CubeDetector(model, surface_model, model_color)\n",
    "Save_2_environ = SaveSystem_by_environment.save_system()\n",
    "Save_2_grip = SaveSystem_by_grip.save_system()\n",
    "\n",
    "Save_2_environ.reset()\n",
    "Save_2_grip.reset()\n",
    "\n",
    "\n",
    "def draw_axis(img, corners, image_points):\n",
    "    corner = tuple(corners[0].ravel())\n",
    "    img = cv2.line(img, corner, tuple(np.int16(image_points[0].ravel())), (255,0,0), 5)\n",
    "    img = cv2.line(img, corner, tuple(np.int16(image_points[1].ravel())), (0,255,0), 5)\n",
    "    img = cv2.line(img, corner, tuple(np.int16(image_points[2].ravel())), (0,0,255), 5)\n",
    "    return img\n",
    "def draw_xy_lines(img, image_points):\n",
    "    img = cv2.line(img, tuple(np.int16(image_points[0].ravel())), tuple(np.int16(image_points[1].ravel())), (0,0,0), 5)\n",
    "    img = cv2.line(img, tuple(np.int16(image_points[1].ravel())), tuple(np.int16(image_points[2].ravel())), (0,0,0), 5)\n",
    "    return img\n",
    "def draw_z_lines(img, image_points):\n",
    "    img = cv2.line(img, tuple(np.int16(image_points[1].ravel())), tuple(np.int16(image_points[3].ravel())), (128,128,0), 5)\n",
    "    return img\n",
    "\n",
    "object_points = np.array( #中心\n",
    "    [\n",
    "        [-25, -25, 0],  # 1\n",
    "        [-25, 25, 0],  # 2\n",
    "        [25, 25, 0],  # 3\n",
    "        [25, -25, 0],  # 4\n",
    "    ],\n",
    "    dtype=np.float32,\n",
    ")\n",
    "\n",
    "#-------------------抓環境座標----------------------\n",
    "cap = cv2.VideoCapture(1,cv2.CAP_DSHOW)\n",
    "\n",
    "fixed_to_table = np.float32(\n",
    "    [[0, 1, 0, -650],\n",
    "     [1, 0, 0, -250],\n",
    "     [0, 0, -1, 860],\n",
    "     [0, 0, 0, 1]])\n",
    "_, table_rmtx, table_tvec, _, _, _, _  = cv2.decomposeProjectionMatrix(fixed_to_table[0:3,0:])\n",
    "\n",
    "table_rvec, _ = cv2.Rodrigues(table_rmtx)\n",
    "table_tvec = fixed_to_table[0:3,3]\n",
    "print(table_tvec)   \n",
    "\n",
    "# color = \"yellow\"\n",
    "while True:\n",
    "    cap_success, frame = cap.read()\n",
    "    if cap_success:\n",
    "        height = 480\n",
    "        scale = height / frame.shape[0]\n",
    "        frame = cv2.resize(frame, None, fx=scale, fy=scale, interpolation=cv2.INTER_LINEAR)\n",
    "        #  將圖片丟入偵測器進行偵測\n",
    "        result_img = detector.detect(frame, index=None, color=\"yellow\",show_process_img=True)\n",
    "        \n",
    "        # 讀取抓到的角點座標\n",
    "        for color_name in list(detector.cube_contour_outer.keys()):\n",
    "            cube_imagePoints = detector.get_cube_sequence_imagePoints(color_name)\n",
    "            if cube_imagePoints is None:\n",
    "                cv2.imshow(\"result\", frame)\n",
    "                if cv2.waitKey(1) & 0xFF == ord(\"q\"):\n",
    "                    break\n",
    "                continue\n",
    "            # 依順序定出對應真實世界對應座標\n",
    "            cube_objectPoints = np.array(\n",
    "                [(0, 0, 0), (0, 50, 0), (50, 50, 0),\n",
    "                (50, 0, 0), (50, 0, -50), (0, 0, -50)]\n",
    "            )\n",
    "            # 如果抓到六個點採用EPNP算法(較準確穩定)，四個點則是一般算法\n",
    "            print(type(cube_imagePoints),'\\n',f\"{cube_imagePoints}\")\n",
    "            if cube_imagePoints.shape[0] == 6:\n",
    "                PnP_success, cube_rvec, cube_tvec = cv2.solvePnP(\n",
    "                    cube_objectPoints.astype(float), cube_imagePoints, mtx, dist, flags=cv2.SOLVEPNP_EPNP)\n",
    "            elif cube_imagePoints.shape[0] == 4:\n",
    "                PnP_success, cube_rvec, cube_tvec = cv2.solvePnP(\n",
    "                    cube_objectPoints[:4].astype(float), cube_imagePoints, mtx, dist)\n",
    "            #  若成功計算出來則計算出該方塊相對於桌面座標系的座標位置\n",
    "            if PnP_success:\n",
    "                R1, _ = cv2.Rodrigues(cube_rvec)  # 創建方塊到相機座標系的旋轉矩陣\n",
    "                R2, _ = cv2.Rodrigues(table_rvec)  # 創建桌面到方塊座標系的旋轉矩陣\n",
    "                T1 = np.eye(4)  # 創建4*4單位矩陣\n",
    "                T2 = np.eye(4)\n",
    "                T1[:3, :3], T1[:3, 3] = R1, cube_tvec.T  #  方塊座標系旋轉後平移到相機座標系 轉換矩陣\n",
    "                T2[:3, :3], T2[:3, 3] = R2, table_tvec.T  # 桌面座標系旋轉後平移到相機座標系 轉換矩陣\n",
    "                T2 = np.linalg.inv(T2)  # 取逆矩陣，變成 相譏座標系到桌面座標系 轉換矩陣\n",
    "                # fixed_to_table = np.linalg.inv(fixed_to_table)  # 取逆矩陣，變成 相譏座標系到桌面座標系 轉換矩陣\n",
    "                transform_matrix = T2 @ T1  # 結合二者，得到方塊座標系到桌面座標系的轉換矩陣\n",
    "                transformed_point = (transform_matrix @ np.array([[25, 25, -25, 1]]).T)  # 傳入方塊正中央座標，即可得到方塊在桌面座標位置了\n",
    "                # 输出结果\n",
    "                print(\"物體在桌面座標系下的座標:\\n\", transformed_point)\n",
    "            # xyz座標位置線繪製\n",
    "            x, y, z = transformed_point[0:3].flatten()\n",
    "\n",
    "            xyz_line_points = np.float32([[0, y, 0], [x, y, 0], [x, 0, 0], [x, y, z]]).reshape(-1, 3)\n",
    "            xyz_line_points_img, _ = cv2.projectPoints(xyz_line_points, table_rvec, table_tvec, mtx, dist)\n",
    "            result_img = draw_xy_lines(result_img, xyz_line_points_img)\n",
    "            result_img = draw_z_lines(result_img, xyz_line_points_img)\n",
    "            print(x, y)        # xyz座標軸繪製\n",
    "            axis = np.float32([[25, 0, 0], [0, 25, 0], [0, 0, 25]]).reshape(-1, 3)\n",
    "            axis_cube_img_points, _ = cv2.projectPoints(axis, cube_rvec, cube_tvec, mtx, dist)\n",
    "            # axis_table_img_points, _ = cv2.projectPoints(axis, table_rvec, table_tvec, mtx, dist)\n",
    "            result_img = draw_axis(result_img, cube_imagePoints.astype(int), axis_cube_img_points)\n",
    "            # result_img = draw_axis(result_img, table_imagePoints.astype(int), axis_table_img_points)\n",
    "\n",
    "        # 取得方塊輪廓計算方塊重心位置\n",
    "        \n",
    "        \n",
    "            print(color_name)\n",
    "            contour_outer = detector.get_cube_contour_outer(color_name)\n",
    "            radius = int(0.08 * cv2.arcLength(contour_outer, True))\n",
    "            print(radius)\n",
    "            M = cv2.moments(contour_outer)\n",
    "            if M[\"m00\"] != 0:\n",
    "                centroid_X = int(M[\"m10\"] / M[\"m00\"])  # 算形心x\n",
    "                centroid_Y = int(M[\"m01\"] / M[\"m00\"])  # 算形心y\n",
    "            # 繪製重心座標點\n",
    "            result_img = cv2.circle(result_img, (centroid_X, centroid_Y), radius, (255, 0, 255), 2)\n",
    "\n",
    "            # 繪製PNP計算所得座標點\n",
    "            predict_cube_center_imagePoint = cv2.projectPoints(np.float32([x, y, z]), table_rvec, table_tvec, mtx, dist)\n",
    "            predict_cube_center_imagePoint = predict_cube_center_imagePoint[0].astype(np.int16)\n",
    "\n",
    "            cv2.putText(result_img, f\"{x=:.1f}, {y=:.1f}, {z=:.1f}\", (10, 40),\n",
    "                        cv2.FONT_HERSHEY_SIMPLEX, 1, (128, 0, 128), 2,)\n",
    "\n",
    "            # 推算是否位置估計錯誤\n",
    "            if (np.linalg.norm(np.array((centroid_X, centroid_Y)) - predict_cube_center_imagePoint) > radius):\n",
    "                cv2.putText(result_img, f\"Error\", (10, 200), cv2.FONT_HERSHEY_SIMPLEX, 2, (0, 0, 255), 4,)\n",
    "                result_img = cv2.circle(result_img, predict_cube_center_imagePoint.ravel(), 5, (0, 0, 255), -1)\n",
    "            else:\n",
    "                cv2.putText(result_img, f\"Ok\", (10, 200), cv2.FONT_HERSHEY_SIMPLEX, 2, (0, 255, 0), 4,)\n",
    "                result_img = cv2.circle(result_img, predict_cube_center_imagePoint.ravel(), 5, (0, 255, 0), -1)\n",
    "                # print(f\"{type(color_name)=}\")\n",
    "                x,y,z = transformed_point[0:3]\n",
    "                # print(f\"{x=}\")\n",
    "                # print(f\"{y=}\")\n",
    "                # print(f\"{z=}\")\n",
    "                Save_2_environ.save_coordinate_by_color(color_name,x, y, z, 10)\n",
    "\n",
    "        cv2.imshow(\"result\", result_img)\n",
    "        Key = cv2.waitKey(1)\n",
    "        if Key == 27:\n",
    "            break\n",
    "        if cv2.waitKey(1) & 0xFF == ord(\"q\"):\n",
    "            break\n",
    "        if Save_2_environ.completed_Save == True:\n",
    "            break\n",
    "    else:\n",
    "        break\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "from ultralytics import YOLO\n",
    "\n",
    "# Load the YOLOv8 model\n",
    "model = YOLO('./cube_surface.pt')\n",
    "\n",
    "# Open the video file\n",
    "video_path = 1\n",
    "cap = cv2.VideoCapture(video_path,cv2.CAP_DSHOW)\n",
    "\n",
    "# Loop through the video frames\n",
    "while cap.isOpened():\n",
    "    # Read a frame from the video\n",
    "    success, frame = cap.read()\n",
    "\n",
    "    if success:\n",
    "        # Run YOLOv8 inference on the frame\n",
    "        results = model(frame,conf=0.8)\n",
    "        # if result.boxes.conf\n",
    "        # Visualize the results on the frame\n",
    "        annotated_frame = results[0].plot(labels=False)\n",
    "\n",
    "        # Display the annotated frame\n",
    "        cv2.imshow(\"YOLOv8 Inference\", annotated_frame)\n",
    "\n",
    "        # Break the loop if 'q' is pressed\n",
    "        if cv2.waitKey(1) & 0xFF == ord(\"q\"):\n",
    "            break\n",
    "    else:\n",
    "        # Break the loop if the end of the video is reached\n",
    "        break\n",
    "\n",
    "# Release the video capture object and close the display window\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array([      17.17,      -15.16,       38.67])]\n"
     ]
    }
   ],
   "source": [
    "grip_coor = Save_2_grip.get_coordinates_by_test(\"green\")\n",
    "print(grip_coor)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "yolov8_segmentation",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
