{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ultralytics import YOLO\n",
    "import numpy as np\n",
    "import cv2\n",
    "import pickle\n",
    "import catcher as CT\n",
    "\n",
    "import torch\n",
    "print(torch.cuda.is_available())\n",
    "\n",
    "model_part = YOLO(\"cube_surface_seg2.pt\")\n",
    "model_region = YOLO(\"yolov8n-seg-custom.pt\")\n",
    "\n",
    "with open('./hand_matrix/calibration.pkl', 'rb') as file:\n",
    "    camera_matrix, dist_coeff = pickle.load(file)\n",
    "# print(camera_matrix, dist_coeff)\n",
    "# with open('./hand_matrix/camMatrix.npy', 'rb') as file:\n",
    "#     m_camera_matrix = np.load(file)\n",
    "# with open('./hand_matrix/distCoef.npy', 'rb') as file:\n",
    "#     m_dist_coeff = np.load(file)\n",
    "# print(m_camera_matrix, m_dist_coeff)\n",
    "    \n",
    "CT = CT.block_detect(model_part=model_part, model_region=model_region)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#HSV\n",
    "def empty(v):\n",
    "    pass\n",
    "\n",
    "block = cv2.imread('block_2.jpg')\n",
    "block = cv2.resize(block, (0, 0), fx=0.1, fy=0.1)\n",
    "\n",
    "cv2.namedWindow('TrackBar')\n",
    "cv2.resizeWindow('TrackBar', 640, 320)\n",
    "\n",
    "cv2.createTrackbar('Hue Min', 'TrackBar', 0, 179, empty)\n",
    "cv2.createTrackbar('Hue Max', 'TrackBar', 179, 179, empty)\n",
    "cv2.createTrackbar('Sat Min', 'TrackBar', 0, 255, empty)\n",
    "cv2.createTrackbar('Sat Max', 'TrackBar', 255, 255, empty)\n",
    "cv2.createTrackbar('Val Min', 'TrackBar', 0, 255, empty)\n",
    "cv2.createTrackbar('Val Max', 'TrackBar', 255, 255, empty)\n",
    "\n",
    "hsv = cv2.cvtColor(block,cv2.COLOR_BGR2HSV)\n",
    "while True:\n",
    "    h_min = cv2.getTrackbarPos('Hue Min', 'TrackBar')\n",
    "    h_max = cv2.getTrackbarPos('Hue Max', 'TrackBar')\n",
    "    s_min = cv2.getTrackbarPos('Sat Min', 'TrackBar')\n",
    "    s_max = cv2.getTrackbarPos('Sat Max', 'TrackBar')\n",
    "    v_min = cv2.getTrackbarPos('Val Min', 'TrackBar')\n",
    "    v_max = cv2.getTrackbarPos('Val Max', 'TrackBar')\n",
    "    print(h_min, h_max, s_min, s_max, v_min, v_max)\n",
    "    \n",
    "    lower = np.array([h_min, s_min, v_min])\n",
    "    upper = np.array([h_max, s_max, v_max])\n",
    "    \n",
    "    mask = cv2.inRange(hsv, lower, upper)\n",
    "    result = cv2.bitwise_and(block, block, mask=mask)\n",
    "\n",
    "    cv2.imshow('block', block)\n",
    "    # cv2.imshow('hsv', hsv)\n",
    "    cv2.imshow('mask', mask)\n",
    "    cv2.imshow('result', result)\n",
    "    \n",
    "\n",
    "    key = cv2.waitKey(1)\n",
    "    if key == 27:\n",
    "        break\n",
    "\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv2.imread(\"block_2.jpg\")\n",
    "# img = cv2.imread(\"123.jpg\")\n",
    "img = cv2.resize(img, (640, 480))\n",
    "\n",
    "object_points = np.array([\n",
    "    [0,0,0],#1\n",
    "    [0,25,0],#2\n",
    "    [25,25,0],#3\n",
    "    [25,0,0],#4\n",
    "    [0,0,25],#5\n",
    "    [0,25,25],#6\n",
    "    [25,25,25],#7\n",
    "    [25,0,25],#8\n",
    "], dtype=np.float32)\n",
    "\n",
    "text_offset = 0\n",
    "\n",
    "text_img = np.zeros((img.shape[0], img.shape[1], 3), dtype=np.uint8)\n",
    "for image_points in CT.detect_parts(img, 2):\n",
    "    # image_points = np.array(image_points, dtype=np.float32)\n",
    "    print(len(image_points))\n",
    "    for color_name, rgb in CT.get_color_text(img):\n",
    "        image_points = np.float32(image_points)\n",
    "        retval, rvec, tvec = cv2.solvePnP(object_points[:4], image_points, camera_matrix, dist_coeff)\n",
    "        z = tvec[2]\n",
    "        x = tvec[0]\n",
    "        y = tvec[1] \n",
    "\n",
    "        rotation_matrix, _ = cv2.Rodrigues(rvec)\n",
    "\n",
    "        # 使用旋转矩阵计算欧拉角（roll-pitch-yaw 顺序）\n",
    "        yaw = np.arctan2(rotation_matrix[1, 0], rotation_matrix[0, 0])\n",
    "        pitch = np.arctan2(-rotation_matrix[2, 0], np.sqrt(rotation_matrix[2, 1]**2 + rotation_matrix[2, 2]**2))\n",
    "        roll = np.arctan2(rotation_matrix[2, 1], rotation_matrix[2, 2])\n",
    "\n",
    "        # 将弧度转换为度数\n",
    "        yaw_deg = np.degrees(yaw)\n",
    "        pitch_deg = np.degrees(pitch)\n",
    "        roll_deg = np.degrees(roll)\n",
    "\n",
    "        xyz_str = [f\"{c}: {v[0]:.2f}\" for c, v in zip(\"xyz\", [x, y, z])]\n",
    "        text_rotation = (5, 15 + text_offset)\n",
    "        text_position = (5, 15 + text_offset)\n",
    "        cv2.putText(text_img, f\"{color_name} {', '.join(xyz_str)}\", text_position, cv2.FONT_HERSHEY_SIMPLEX, 0.5, rgb, 2)\n",
    "        # cv2.putText(text_img, f\"Yaw: {yaw_deg:.1f}, Pitch: {pitch_deg:.1f}, Roll: {roll_deg:.1f}\", text_rotation, cv2.FONT_HERSHEY_SIMPLEX, 0.5, rgb, 2)\n",
    "        result_image = cv2.addWeighted(img, 1, text_img, 1, 0)\n",
    "        text_offset += 17\n",
    "\n",
    "cv2.imshow('img', result_image)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import robot.robot as bot\n",
    "import socket\n",
    "\n",
    "TCP_IP = \"192.168.0.1\"  #  Robot IP address. Start the TCP server from the robot before starting this code\n",
    "TCP_PORT = 3000  #  Robot Port\n",
    "BUFFER_SIZE = 1024  #  Buffer size of the channel, probably 1024 or 4096\n",
    "\n",
    "gripper_port = '/dev/ttyUSB2'  # gripper USB port to linux\n",
    "# gripper_port = \"COM8\"  # gripper USB port to windows\n",
    "\n",
    "global c\n",
    "c = socket.socket(socket.AF_INET, socket.SOCK_STREAM)  #  Initialize the communication the robot through TCP as a client, the robot is the server.\n",
    "#  Connect the ethernet cable to the robot electric box first\n",
    "c.connect((TCP_IP, TCP_PORT))\n",
    "arm  = bot.robot.robotic_arm(gripper_port,c)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.spatial.transform import Rotation as R\n",
    "\n",
    "def transform_matrix(x, y, z, rx, ry, rz):\n",
    "    # 轉換為弧度\n",
    "    rx, ry, rz = np.radians(rx), np.radians(ry), np.radians(rz)\n",
    "\n",
    "    # 計算旋轉矩陣\n",
    "    rotation_matrix = R.from_euler('xyz', [rx, ry, rz], degrees=False).as_matrix()\n",
    "\n",
    "    # 構建轉移矩陣\n",
    "    transformation_matrix = np.vstack([np.hstack([rotation_matrix, np.array([[x], [y], [z]])]),\n",
    "                                      np.array([0, 0, 0, 1])])\n",
    "\n",
    "    return transformation_matrix\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lens = cv2.VideoCapture(2,cv2.CAP_ANY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lens.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# object_points = np.array([\n",
    "#     [0,0,0],#1\n",
    "#     [0,25,0],#2\n",
    "#     [25,25,0],#3\n",
    "#     [25,0,0],#4\n",
    "#     [0,0,25],#5\n",
    "#     [0,25,25],#6\n",
    "#     [25,25,25],#7\n",
    "#     [25,0,25],#8\n",
    "# ], dtype=np.float32)\n",
    "\n",
    "# with open('./Hcam2Grip/h_c2g.npy','rb') as file:\n",
    "#     Hcam2Grip = np.load(file)\n",
    "# print(Hcam2Grip)\n",
    "\n",
    "# object_points = np.array([\n",
    "#     [-12.5,-12.5,0],#1\n",
    "#     [-12.5,12.5,0],#2\n",
    "#     [12.5,12.5,0],#3\n",
    "#     [12.5,-12.5,0],#4\n",
    "# ], dtype=np.float32)\n",
    "object_points = np.array(\n",
    "    [\n",
    "        [-25, -25, 0],  # 1\n",
    "        [-25, 25, 0],  # 2\n",
    "        [25, 25, 0],  # 3\n",
    "        [25, -25, 0],  # 4\n",
    "    ],\n",
    "    dtype=np.float32,\n",
    ")\n",
    "\n",
    "offset_x = 0\n",
    "offset_y = 0\n",
    "\n",
    "while True:\n",
    "    ret, frame = lens.read()\n",
    "    # frame = cv2.flip(frame, -1)\n",
    "    # frame = cv2.resize(frame, (640, 480))\n",
    "    # if not ret:\n",
    "    #     print(123)\n",
    "    #     break\n",
    "    vertical_offset = 0\n",
    "    for image_points in CT.detect_parts(frame):\n",
    "        for color_name, rgb in CT.get_color_text(frame):\n",
    "            image_points = np.float32(image_points)\n",
    "            retval, rvec, tvec = cv2.solvePnP(\n",
    "                object_points[:4], image_points, camera_matrix, dist_coeff\n",
    "            )\n",
    "            if retval:\n",
    "                x = tvec[0] - offset_x\n",
    "                y = tvec[1] - offset_y\n",
    "                z = tvec[2]\n",
    "                rotation_matrix, _ = cv2.Rodrigues(rvec)\n",
    "                # 使用旋转矩阵计算欧拉角（roll-pitch-yaw 顺序）\n",
    "                yaw = np.arctan2(rotation_matrix[1, 0], rotation_matrix[0, 0])\n",
    "                pitch = np.arctan2(\n",
    "                    -rotation_matrix[2, 0],\n",
    "                    np.sqrt(rotation_matrix[2, 1] ** 2 + rotation_matrix[2, 2] ** 2),\n",
    "                )\n",
    "                roll = np.arctan2(rotation_matrix[2, 1], rotation_matrix[2, 2])\n",
    "                # 将弧度转换为度数\n",
    "                yaw_deg = np.degrees(yaw)\n",
    "                pitch_deg = np.degrees(pitch)\n",
    "                roll_deg = np.degrees(roll)\n",
    "\n",
    "                text_loc_tvec = (5, 15 + vertical_offset)\n",
    "                text_loc_rvec = (5, 32 + vertical_offset)\n",
    "                text_loc_check = (400, 15 + vertical_offset)\n",
    "\n",
    "                xyz_str = [f\"{c}: {v[0]:.2f}\" for c, v in zip(\"xyz\", [x, y, z])]\n",
    "                cv2.putText(\n",
    "                    frame,\n",
    "                    f\"{color_name} {', '.join(xyz_str)}\",\n",
    "                    text_loc_tvec,\n",
    "                    cv2.FONT_HERSHEY_SIMPLEX,\n",
    "                    0.5,\n",
    "                    rgb,\n",
    "                    2,\n",
    "                )\n",
    "                cv2.putText(\n",
    "                    frame,\n",
    "                    f\"Rotate Z: {yaw_deg:.1f},   Rotate Y: {pitch_deg:.1f},   Rotate X: {roll_deg:.1f}\",\n",
    "                    text_loc_rvec,\n",
    "                    cv2.FONT_HERSHEY_SIMPLEX,\n",
    "                    0.5,\n",
    "                    rgb,\n",
    "                    2,\n",
    "                )\n",
    "                if -10 < x < 10 and -10 < y < 10:\n",
    "                    cv2.putText(\n",
    "                        frame,\n",
    "                        \"OK\",\n",
    "                        text_loc_check,\n",
    "                        cv2.FONT_HERSHEY_SIMPLEX,\n",
    "                        0.5,\n",
    "                        (0, 255, 0),\n",
    "                        2,\n",
    "                    )\n",
    "                else:\n",
    "                    cv2.putText(\n",
    "                        frame,\n",
    "                        \"Moving\",\n",
    "                        text_loc_check,\n",
    "                        cv2.FONT_HERSHEY_SIMPLEX,\n",
    "                        0.5,\n",
    "                        (0, 0, 255),\n",
    "                        2,\n",
    "                    )\n",
    "                cv2.circle(frame, (int(x[0]), int(y[0])), 5, (0, 0, 255), -1)\n",
    "                vertical_offset += 34\n",
    "                target = np.array([[x[0], y[0], 509, 1]]).T\n",
    "\n",
    "                theta = -60\n",
    "                theta = np.radians(theta)\n",
    "                Hcam2Grip = np.array(\n",
    "                    [\n",
    "                        [-0.4681, -0.88351, 0.017186, -0],\n",
    "                        [0.88269, -0.46841, -0.03817, 23.43],\n",
    "                        [0.041773, -0.0026981, 0.99912, -71.743],\n",
    "                        [0, 0, 0, 1],\n",
    "                    ]\n",
    "                )\n",
    "                final_target = (\n",
    "                    transform_matrix(211, 468, 509, -180, 0, -60) @ Hcam2Grip @ target\n",
    "                )\n",
    "                # grip2 = np.linalg.inv(transform_matrix(251,494,509,-180, 0, -60)) @ np.eye(4)\n",
    "                # print(grip2)\n",
    "                print(final_target)\n",
    "    else:\n",
    "        pass\n",
    "    cv2.imshow(\"test\", frame)\n",
    "    key = cv2.waitKey(1)\n",
    "    if key == 27:\n",
    "        print(123)\n",
    "        break\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.spatial.transform import Rotation as R\n",
    "\n",
    "\n",
    "def calculate_transform_matrix(initial_position, final_position):\n",
    "    # 初始座標和移動後的座標\n",
    "    p1 = np.array(initial_position)\n",
    "    p2 = np.array(final_position)\n",
    "\n",
    "    # 計算平移向量\n",
    "    translation_vector = p2 - p1\n",
    "\n",
    "    # 計算旋轉矩陣\n",
    "    direction = p2 - p1\n",
    "    axis = np.cross(np.array([1, 0, 0]), direction)\n",
    "    angle = np.arccos(np.dot(np.array([1, 0, 0]), direction) / (np.linalg.norm(direction)))\n",
    "\n",
    "    rotation_matrix = R.from_rotvec(axis * angle).as_matrix()\n",
    "\n",
    "    # 構建轉移矩陣\n",
    "    transformation_matrix = np.vstack([np.hstack([rotation_matrix, translation_vector.reshape(3, 1)]),\n",
    "                                      np.array([0, 0, 0, 1])])\n",
    "\n",
    "    return transformation_matrix\n",
    "np.linalg.inv(transform_matrix(200,500,509,-180, 0, -60)) @ calculate_transform_matrix([0,0,509],[200,500,509])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "yolov8_segmentation",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
